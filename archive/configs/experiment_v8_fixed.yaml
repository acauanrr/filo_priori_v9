# Filo-Priori V8 - FIXED Configuration
# Correções para o colapso de predição
#
# PROBLEMAS CORRIGIDOS:
# 1. Focal Loss alpha INVERTIDO: [0.15,0.85] → [0.995,0.005]
# 2. Binary strategy ERRADO: pass_vs_all → pass_vs_fail (CRÍTICO!)
# 3. Learning rate muito baixo: 5e-5 → 1e-4
# 4. Weight decay muito alto: 2e-4 → 5e-5
# 5. Dropout muito alto: 0.3-0.4 → 0.2-0.3
# 6. Early stopping muito agressivo: patience 12 → 20
# 7. Threshold search range muito restrito: [0.2,0.8] → [0.1,0.9]
#
# MUDANÇA CRÍTICA: pass_vs_fail strategy
# - ANTES: Pass vs Not-Pass (incluía Delete/Blocked/etc.) - 88.5%/11.5% (7.7:1)
# - AGORA: Pass vs Fail APENAS - 97.4%/2.6% (37:1) - muito mais desbalanceado!
# - Focal Loss ajustado: alpha=[0.995, 0.005], gamma=3.5

experiment:
  name: "v8_fixed"
  version: "8.0.1"
  description: "V8 with fixed focal loss and hyperparameters to prevent prediction collapse"
  seed: 42

# Data Configuration (unchanged)
data:
  train_path: "datasets/train.csv"
  test_path: "datasets/test.csv"

  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42

  binary_classification: true
  binary_strategy: "pass_vs_fail"  # ✅ CHANGED: Only Pass vs Fail (excludes Delete/Blocked/etc.)
  binary_positive_class: "Pass"  # Class 1
  binary_negative_class: "Fail"  # Class 0 (ONLY Fail, not Not-Pass)

  smote:
    enabled: false
    k_neighbors: 5
    sampling_strategy: "auto"

# Text Processing Configuration (unchanged)
text:
  num_commits_to_keep: 3
  max_commit_length: 512
  max_summary_length: 256
  max_steps_length: 512

# Semantic Embeddings (unchanged)
semantic:
  model_name: "models/finetuned_bge_v1"
  embedding_dim: 1024
  max_length: 512
  batch_size: 32
  pooling_strategy: "mean"
  normalize_embeddings: true
  cache_path: "cache/embeddings"

  fields:
    - "TE_Summary"
    - "TC_Steps"
    - "commit"

# Structural Features (unchanged)
structural:
  extractor:
    recent_window: 5
    min_history: 2
    cache_path: "cache/structural_features.pkl"

  input_dim: 6

# Phylogenetic Graph (unchanged)
graph:
  type: "co_failure"
  min_co_occurrences: 2
  weight_threshold: 0.1
  cache_path: "cache/phylogenetic_graph.pkl"
  build_graph: true

# Model Architecture - REDUCED DROPOUT
model:
  type: "dual_stream_v8"

  # Semantic Stream - LESS REGULARIZATION
  semantic:
    input_dim: 1024
    hidden_dim: 256
    num_layers: 2
    dropout: 0.2  # ✅ REDUCED from 0.3
    activation: "gelu"

  # Structural Stream - LESS REGULARIZATION
  structural:
    input_dim: 6
    hidden_dim: 256
    num_heads: 4
    dropout: 0.2  # ✅ REDUCED from 0.3
    activation: "elu"
    use_edge_weights: true

  # Fusion Layer (unchanged)
  fusion:
    type: "cross_attention"
    num_heads: 4
    dropout: 0.1

  # Classifier - LESS REGULARIZATION
  classifier:
    hidden_dims: [128, 64]
    dropout: 0.3  # ✅ REDUCED from 0.4

  num_classes: 2

# Training Configuration - ADJUSTED
training:
  num_epochs: 50  # ✅ INCREASED from 40
  batch_size: 32
  learning_rate: 1e-4  # ✅ DOUBLED from 5e-5
  weight_decay: 5e-5  # ✅ REDUCED 4x from 2e-4

  optimizer:
    type: "AdamW"
    betas: [0.9, 0.999]
    eps: 1e-8

  scheduler:
    type: "cosine"
    T_max: 50  # ✅ Match num_epochs
    eta_min: 1e-6

  grad_clip_norm: 1.0

  # Early stopping - MORE PATIENT
  early_stopping:
    enabled: true
    patience: 20  # ✅ INCREASED from 12
    monitor: "val_f1_macro"
    mode: "max"
    min_delta: 0.001  # ✅ ADDED - require meaningful improvement

  use_amp: false

# Loss Function - CRITICAL FIX!!!
loss:
  type: "focal"

  # Focal Loss parameters - CORRECTED ALPHA (pass_vs_fail strategy)
  focal:
    # ✅ EXTREMELY AGGRESSIVE for 97%/3% imbalance (37:1 ratio)
    # alpha[0] = weight for Fail (minority class, 2.6%) → VERY HIGH (0.995)
    # alpha[1] = weight for Pass (majority class, 97.4%) → VERY LOW (0.005)
    alpha: [0.995, 0.005]  # ✅ More aggressive for pass_vs_fail (was [0.98, 0.02] for pass_vs_all)
    gamma: 3.5  # ✅ INCREASED from 3.0 for even stronger focusing

  # Alternative: Weighted CE (if focal still doesn't work)
  weighted_ce:
    use_class_weights: true
    # Ratio with pass_vs_fail: 61224 Pass / 1654 Fail = 37:1
    # So weight Fail much higher: [37.0, 1.0]

# Evaluation Configuration - IMPROVED
evaluation:
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision"
    - "recall"
    - "auprc"
    - "confusion_matrix"
    - "prediction_diversity"  # ✅ ADDED - monitor collapse

  temperature_scaling:
    enabled: true
    initial_T: 1.0

  # Threshold search - WIDER RANGE
  threshold_search:
    enabled: true
    search_range: [0.1, 0.9]  # ✅ EXPANDED from [0.2, 0.8]
    search_step: 0.05
    metric: "f1_macro"

# APFD Configuration (unchanged)
apfd:
  expected_builds: 277
  count_tc_1_rule: true
  only_fail_results: true
  save_prioritized_tests: true
  save_apfd_per_build: true

# Logging Configuration (unchanged)
logging:
  level: "INFO"
  log_to_file: true
  log_file: "logs/experiment_v8_fixed.log"
  log_to_tensorboard: true
  tensorboard_dir: "runs/experiment_v8_fixed"

  checkpoint:
    save_best: true
    save_last: true
    save_every_n_epochs: 10

# Output Configuration
output:
  results_dir: "results/experiment_v8_fixed"
  save_predictions: true
  save_features: true
  save_confusion_matrix: true
  save_pr_curves: true

# Hardware Configuration (unchanged)
hardware:
  device: "cuda"
  num_workers: 4
  pin_memory: true

# ============================================================================
# EXPECTED IMPROVEMENTS (pass_vs_fail strategy):
# ============================================================================
# DATASET CHANGES:
# - Training samples: ~62,878 (61,224 Pass + 1,654 Fail only)
# - EXCLUDES: Delete (3,653), Blocked (1,862), Conditional Pass (654), etc.
# - Class ratio: 97.4% Pass / 2.6% Fail (37:1 - EXTREMELY imbalanced!)
#
# EXPECTED METRICS:
# 1. Recall Fail: 0.00% → ≥30% (detect at least 30% of actual Fail cases)
# 2. Prediction Diversity: ~0.0 → ≥0.20 (both classes being predicted)
# 3. F1 Macro: 0.47 → ≥0.55 (balanced performance between Pass and Fail)
# 4. APFD: 0.497 → ≥0.55 (better test prioritization)
# 5. Precision Fail: ≥30% (when predicting Fail, be right ≥30% of time)
#
# SUCCESS CRITERIA (GO):
# - Prediction Diversity ≥ 0.20 (both classes being predicted)
# - Recall Fail ≥ 0.30 (detecting at least 30% of Fail cases)
# - Precision Fail ≥ 0.25 (avoid too many false alarms)
# - F1 Macro ≥ 0.50 (balanced performance)
# - Test Accuracy ≥ 0.80 (overall performance should be high with 97% Pass baseline)
#
# NO-GO CRITERIA (FAILURE):
# - Prediction Diversity < 0.10 (still collapsing)
# - Recall Fail < 0.20 (not detecting failures)
# - F1 Macro < 0.45 (no improvement)
# ============================================================================
