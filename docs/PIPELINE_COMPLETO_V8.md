# Pipeline Completo Filo-Priori V8

**Data**: 2025-11-07
**Status**: âœ… **PRONTO PARA EXECUÃ‡ÃƒO**

---

## ğŸ“‹ VISÃƒO GERAL

Pipeline completo do Filo-Priori V8 com todas as correÃ§Ãµes, imputaÃ§Ãµes e processamento do test.csv completo implementado.

---

## ğŸš€ EXECUÃ‡ÃƒO

```bash
python main_v8.py --config configs/experiment_v8_fixed.yaml --device cuda
```

**DuraÃ§Ã£o estimada**: 2-3 horas (treino completo + processamento test.csv)

---

## ğŸ“Š PIPELINE COMPLETO (6 STEPS)

### STEP 1: DATA PREPARATION

```
1.1: Loading datasets (train.csv)
     â”œâ”€â”€ Split: 80% train / 10% val / 10% test
     â”œâ”€â”€ Strategy: pass_vs_fail (APENAS Pass vs Fail)
     â””â”€â”€ Samples excluÃ­dos: Delete, Blocked, Conditional Pass, etc.

1.2: Generating semantic embeddings (BGE)
     â”œâ”€â”€ Model: models/finetuned_bge_v1
     â”œâ”€â”€ Dim: 1024
     â”œâ”€â”€ Fields: TE_Summary + TC_Steps + commit
     â””â”€â”€ Caching: cache/embeddings/

1.3: Extracting structural features
     â”œâ”€â”€ Features: [test_age, failure_rate, recent_failure_rate,
     â”‚              flakiness_rate, commit_count, test_novelty]
     â”œâ”€â”€ Fitted on training data
     â”œâ”€â”€ Global statistics computed (means, medians, stds)
     â””â”€â”€ Caching: cache/structural_features.pkl

1.3b: Imputing missing structural features
      â”œâ”€â”€ Method 1: Semantic Similarity (k=10, threshold=0.5)
      â”œâ”€â”€ Method 2: Fallback conservador (mÃ©dias populacionais)
      â”œâ”€â”€ Validation: ~77% imputaÃ§Ã£o semÃ¢ntica, ~23% fallback
      â””â”€â”€ Adds Gaussian noise to avoid identical features

1.4: Building phylogenetic graph
     â”œâ”€â”€ Type: co_failure
     â”œâ”€â”€ Min co-occurrences: 2
     â”œâ”€â”€ Nodes: test cases
     â”œâ”€â”€ Edges: co-failure relationships
     â””â”€â”€ Caching: cache/phylogenetic_graph.pkl

1.5: Extracting graph structure
     â””â”€â”€ edge_index, edge_weights for GAT
```

### STEP 2: MODEL CREATION

```
2.1: Creating Dual-Stream V8 Model
     â”œâ”€â”€ Semantic Stream: MLP (1024 â†’ 256)
     â”œâ”€â”€ Structural Stream: GAT (6 â†’ 256)
     â”œâ”€â”€ Fusion: Cross-Attention (4 heads)
     â”œâ”€â”€ Classifier: MLP (512 â†’ 128 â†’ 64 â†’ 2)
     â””â”€â”€ Total params: ~2.0M
```

### STEP 3: TRAINING

```
3.1: Loss Function
     â”œâ”€â”€ Type: Focal Loss
     â”œâ”€â”€ Alpha: [0.995, 0.005]  # CRITICAL: invertido e agressivo!
     â”œâ”€â”€ Gamma: 3.5
     â””â”€â”€ Strategy: Penaliza classe majoritÃ¡ria (Pass), foca em Fail

3.2: Training Loop
     â”œâ”€â”€ Epochs: 50
     â”œâ”€â”€ Batch size: 32
     â”œâ”€â”€ Optimizer: AdamW (lr=1e-4, wd=5e-5)
     â”œâ”€â”€ Scheduler: CosineAnnealingLR
     â”œâ”€â”€ Early Stopping: patience=20, monitor=val_f1_macro
     â””â”€â”€ Best model saved: best_model_v8.pt

3.3: Validation per epoch
     â””â”€â”€ Metrics: accuracy, f1_macro, f1_weighted, precision, recall, auprc
```

### STEP 4: TEST EVALUATION (Split)

```
4.1: Load best model
4.2: Evaluate on test split (~10% of train.csv)
4.3: Compute metrics
     â””â”€â”€ Classification report, confusion matrix, PR curves
```

### STEP 5: APFD CALCULATION (Split)

```
5.1: Add probabilities to test DataFrame
     â”œâ”€â”€ probability = P(Fail) = probs[:, 0]
     â””â”€â”€ CRITICAL: Uses TE_Test_Result column for correct labels

5.2: Verify columns
     â”œâ”€â”€ TE_Test_Result: must exist! (original labels)
     â”œâ”€â”€ Build_ID: must exist! (for per-build APFD)
     â””â”€â”€ Validation logs shown

5.3: Generate prioritized CSV
     â”œâ”€â”€ File: results/experiment_v8_fixed/prioritized_test_cases.csv
     â”œâ”€â”€ Columns: Build_ID, TC_Key, TE_Test_Result, label_binary,
     â”‚            probability, diversity_score, priority_score, rank
     â””â”€â”€ Ranks: per-build, 1-indexed (1 = highest priority)

5.4: Calculate APFD per build
     â”œâ”€â”€ File: results/experiment_v8_fixed/apfd_per_build.csv
     â”œâ”€â”€ Only builds with at least 1 Fail
     â”œâ”€â”€ Business rule: builds with 1 TC â†’ APFD=1.0
     â””â”€â”€ Expected: ~10-30 builds (test split is only 10%)

5.5: Print APFD summary
     â””â”€â”€ Mean, median, std, min, max, distribution
```

### STEP 6: PROCESS FULL TEST.CSV (277 BUILDS) â­ NOVO!

```
6.1: Load FULL test.csv
     â”œâ”€â”€ File: datasets/test.csv
     â”œâ”€â”€ Total samples: ~31,333
     â”œâ”€â”€ Total builds: ~1,000+
     â””â”€â”€ Builds with Fail: 277 (expected)

6.2: Generate semantic embeddings for full test
     â”œâ”€â”€ Uses same BGE model
     â”œâ”€â”€ No caching (one-time processing)
     â””â”€â”€ Shape: [31333, 1024]

6.3: Extract structural features for full test
     â”œâ”€â”€ Uses fitted extractor from training
     â”œâ”€â”€ is_test=True (uses historical stats only)
     â””â”€â”€ Shape: [31333, 6]

6.3b: Impute missing features
      â”œâ”€â”€ Identifies which samples need imputation
      â”œâ”€â”€ Uses semantic similarity with training samples
      â””â”€â”€ Fallback to conservative defaults

6.4: Generate predictions on full test
     â”œâ”€â”€ Batch processing (batch_size=32)
     â”œâ”€â”€ Uses best trained model
     â”œâ”€â”€ Structural stream: GAT on full graph once
     â””â”€â”€ Output: [31333, 2] probabilities

6.5: Prepare data for APFD
     â”œâ”€â”€ probability = P(Fail) = probs[:, 0]
     â”œâ”€â”€ label_binary from TE_Test_Result == 'Fail'
     â””â”€â”€ Verify counts: failures vs passes

6.6: Generate prioritized CSV (FULL)
     â”œâ”€â”€ File: results/experiment_v8_fixed/prioritized_test_cases_FULL_testcsv.csv
     â”œâ”€â”€ All 31,333 test cases with ranks per build
     â””â”€â”€ Format: same as split version

6.7: Calculate APFD per build (FULL)
     â”œâ”€â”€ File: results/experiment_v8_fixed/apfd_per_build_FULL_testcsv.csv
     â”œâ”€â”€ Expected: EXACTLY 277 builds
     â”œâ”€â”€ Each row: method_name, build_id, test_scenario, count_tc,
     â”‚             count_commits, apfd, time
     â””â”€â”€ Mean APFD: PRIMARY METRIC!

6.8: Validation
     â”œâ”€â”€ Check: total_builds == 277
     â”œâ”€â”€ SUCCESS if 277, WARNING otherwise
     â””â”€â”€ Log all file paths
```

---

## ğŸ“ ARQUIVOS DE SAÃDA

### Estrutura de Resultados

```
results/experiment_v8_fixed/
â”œâ”€â”€ best_model_v8.pt                              # Melhor modelo treinado
â”œâ”€â”€ config_used.yaml                               # ConfiguraÃ§Ã£o usada
â”œâ”€â”€ confusion_matrix.png                           # Matriz de confusÃ£o (split test)
â”œâ”€â”€ precision_recall_curves.png                    # Curvas PR (split test)
â”œâ”€â”€ prioritized_test_cases.csv                     # Test split prioritizado
â”œâ”€â”€ apfd_per_build.csv                            # APFD do test split (~30 builds)
â”œâ”€â”€ prioritized_test_cases_FULL_testcsv.csv       # â­ FULL test.csv prioritizado (31K)
â””â”€â”€ apfd_per_build_FULL_testcsv.csv               # â­ APFD dos 277 builds (PRINCIPAL!)
```

### DescriÃ§Ã£o dos Arquivos Principais

#### 1. `apfd_per_build_FULL_testcsv.csv` â­ PRINCIPAL

**Formato**:
```csv
method_name,build_id,test_scenario,count_tc,count_commits,apfd,time
v8_fixed_FULL_testcsv,Build_001,full_test_csv_277_builds,45,12,0.6234,0
v8_fixed_FULL_testcsv,Build_002,full_test_csv_277_builds,38,8,0.7891,0
...
```

**EstatÃ­sticas**:
- Total de linhas: **EXATAMENTE 277**
- Colunas:
  - `method_name`: Nome do experimento + "_FULL_testcsv"
  - `build_id`: Identificador do build
  - `test_scenario`: "full_test_csv_277_builds"
  - `count_tc`: NÃºmero de TCs Ãºnicos neste build
  - `count_commits`: NÃºmero de commits Ãºnicos (incluindo CRs)
  - `apfd`: APFD score [0, 1] (higher is better)
  - `time`: Placeholder (0)

**MÃ©trica Principal**: `Mean APFD` (mÃ©dia da coluna `apfd`)

#### 2. `prioritized_test_cases_FULL_testcsv.csv`

**Formato**:
```csv
Build_ID,TC_Key,TE_Test_Result,label_binary,probability,diversity_score,priority_score,rank
Build_001,TC_12345,Fail,1,0.8234,0.0,0.8234,1
Build_001,TC_67890,Pass,0,0.7123,0.0,0.7123,2
Build_001,TC_11111,Pass,0,0.5432,0.0,0.5432,3
...
```

**Total de linhas**: ~31,333 (todos os TCs do test.csv)

**Colunas**:
- `Build_ID`: Build onde o TC foi executado
- `TC_Key`: Identificador Ãºnico do test case
- `TE_Test_Result`: Resultado original ("Pass", "Fail")
- `label_binary`: 1 se Fail, 0 se Pass
- `probability`: P(Fail) predita pelo modelo
- `diversity_score`: Sempre 0.0 (nÃ£o usado em V8)
- `priority_score`: Mesmo que probability
- `rank`: Prioridade no build (1 = mais alta, N = mais baixa)

---

## âœ… VALIDAÃ‡Ã•ES AUTOMÃTICAS

Durante a execuÃ§Ã£o, o pipeline valida:

### 1. Colunas CrÃ­ticas

```
âœ… TE_Test_Result column found with 2 unique values
   Values: {'Pass': 29679, 'Fail': 1654}
âœ… Build_ID column found: 1234 unique builds
```

### 2. ImputaÃ§Ã£o de Features

```
  Validation samples needing imputation: 0/6917 (0.0%)
  Test samples needing imputation: 127/8127 (1.6%)

  Imputation complete:
    Semantic-based: 98 (77.2%)
    Fallback (conservative): 29 (22.8%)
```

### 3. APFD - 277 Builds

```
FINAL APFD RESULTS - FULL TEST.CSV (277 BUILDS)
======================================================================
Total builds analyzed: 277
Mean APFD: 0.XXXX â­ PRIMARY METRIC

VALIDATION
======================================================================
âœ… SUCCESS: Found exactly 277 builds with failures!
âœ… Mean APFD: 0.XXXX
```

**Se nÃ£o encontrar 277**:
```
âš ï¸  WARNING: Expected 277 builds but found XXX
   This may indicate incorrect filtering or data issues
```

---

## ğŸ¯ CRITÃ‰RIOS DE SUCESSO

### MÃ©tricas de ClassificaÃ§Ã£o (Test Split)

| MÃ©trica | GO (Sucesso) | REVIEW | NO-GO |
|---------|--------------|--------|-------|
| **Prediction Diversity** | â‰¥ 0.20 | [0.15, 0.20) | < 0.15 |
| **Recall Fail** | â‰¥ 0.30 | [0.20, 0.30) | < 0.20 |
| **Precision Fail** | â‰¥ 0.25 | [0.20, 0.25) | < 0.20 |
| **F1 Macro** | â‰¥ 0.50 | [0.45, 0.50) | < 0.45 |
| **Test Accuracy** | â‰¥ 0.80 | [0.75, 0.80) | < 0.75 |

### MÃ©tricas de APFD (FULL test.csv) â­ PRINCIPAL

| MÃ©trica | Target | Minimum | Notes |
|---------|--------|---------|-------|
| **Total Builds** | 277 | 277 | **MUST BE EXACT** |
| **Mean APFD** | â‰¥ 0.60 | â‰¥ 0.55 | Higher is better |
| **Median APFD** | â‰¥ 0.65 | â‰¥ 0.60 | Less affected by outliers |
| **Builds APFD â‰¥ 0.7** | â‰¥ 50% | â‰¥ 40% | Good prioritization |
| **Builds APFD < 0.5** | < 20% | < 30% | Random or worse |

---

## ğŸ” COMO VERIFICAR RESULTADOS

### 1. Verificar ExecuÃ§Ã£o Bem-Sucedida

```bash
# Verificar se todos os arquivos foram criados
ls -lh results/experiment_v8_fixed/

# Deve mostrar:
# - best_model_v8.pt
# - apfd_per_build_FULL_testcsv.csv  <-- PRINCIPAL
# - prioritized_test_cases_FULL_testcsv.csv
```

### 2. Validar 277 Builds

```bash
# Contar linhas no arquivo APFD (deve ser 278 = 277 builds + 1 header)
wc -l results/experiment_v8_fixed/apfd_per_build_FULL_testcsv.csv

# Deve mostrar: 278 results/experiment_v8_fixed/apfd_per_build_FULL_testcsv.csv
```

### 3. Calcular Mean APFD

```bash
# Calcular mÃ©dia da coluna APFD (coluna 6)
awk -F',' 'NR>1 {sum+=$6; count++} END {print "Mean APFD:", sum/count; print "Total Builds:", count}' \
    results/experiment_v8_fixed/apfd_per_build_FULL_testcsv.csv
```

**SaÃ­da esperada**:
```
Mean APFD: 0.XXXX
Total Builds: 277
```

### 4. Verificar DistribuiÃ§Ã£o de APFD

```bash
# Contar builds por faixa de APFD
awk -F',' 'NR>1 {
    apfd=$6;
    if (apfd >= 0.7) high++;
    else if (apfd >= 0.5) medium++;
    else low++;
}
END {
    print "APFD >= 0.7:", high;
    print "0.5 <= APFD < 0.7:", medium;
    print "APFD < 0.5:", low;
}' results/experiment_v8_fixed/apfd_per_build_FULL_testcsv.csv
```

---

## ğŸ“Š INTERPRETAÃ‡ÃƒO DE RESULTADOS

### Mean APFD

```
APFD = 1.0:  Perfeito - todas as falhas detectadas primeiro
APFD â‰¥ 0.7:  Excelente - maioria das falhas detectadas cedo
APFD â‰¥ 0.6:  Bom - performance acima da mÃ©dia
APFD â‰¥ 0.55: AceitÃ¡vel - melhor que random (0.5)
APFD â‰¥ 0.5:  Limiar - igual a random
APFD < 0.5:  Ruim - pior que random
```

### Exemplo de Log de Sucesso

```
======================================================================
FINAL APFD RESULTS - FULL TEST.CSV (277 BUILDS)
======================================================================
Total builds analyzed: 277
Total test cases: 31333
Mean TCs per build: 113.1

APFD Statistics:
  Mean:   0.6234 â­ PRIMARY METRIC
  Median: 0.6578
  Std:    0.1234
  Min:    0.2345
  Max:    0.9876

APFD Distribution:
  Builds with APFD = 1.0:   12 (  4.3%)
  Builds with APFD â‰¥ 0.7:  145 ( 52.3%)
  Builds with APFD â‰¥ 0.5:  231 ( 83.4%)
  Builds with APFD < 0.5:   46 ( 16.6%)
======================================================================

VALIDATION
======================================================================
âœ… SUCCESS: Found exactly 277 builds with failures!
âœ… Mean APFD: 0.6234

âœ… All results saved to: results/experiment_v8_fixed/
   - prioritized_test_cases.csv (test split)
   - apfd_per_build.csv (test split)
   - prioritized_test_cases_FULL_testcsv.csv (all 277 builds)
   - apfd_per_build_FULL_testcsv.csv (all 277 builds)
======================================================================

TRAINING COMPLETE!
======================================================================
Best Val F1: 0.5678
Test F1: 0.5432
Mean APFD (test split): 0.5891
Mean APFD (FULL test.csv, 277 builds): 0.6234 â­
======================================================================
```

---

## ğŸ› TROUBLESHOOTING

### Problema 1: NÃ£o encontrou 277 builds

```
âš ï¸  WARNING: Expected 277 builds but found XXX
```

**PossÃ­veis causas**:
1. `binary_strategy` nÃ£o Ã© "pass_vs_fail" â†’ Verifica config
2. test.csv estÃ¡ incompleto â†’ Verifica arquivo
3. Filtros muito agressivos no data_loader â†’ Verifica _clean_data_non_strict

**SoluÃ§Ã£o**:
```bash
# Verificar test.csv diretamente
python -c "
import pandas as pd
df = pd.read_csv('datasets/test.csv')
print(f'Total samples: {len(df)}')
print(f'Total builds: {df[\"Build_ID\"].nunique()}')
builds_fail = df[df['TE_Test_Result'] == 'Fail']['Build_ID'].nunique()
print(f'Builds with Fail: {builds_fail}')
"
```

### Problema 2: TE_Test_Result nÃ£o encontrado

```
âŒ CRITICAL: TE_Test_Result column not found in test DataFrame!
```

**Causa**: DataLoader estÃ¡ dropando a coluna

**SoluÃ§Ã£o**: Verificar que `load_full_test_dataset()` estÃ¡ preservando todas as colunas.

### Problema 3: Out of Memory durante Step 6

**Causa**: Test.csv completo Ã© muito grande para processar de uma vez

**SoluÃ§Ã£o**:
```python
# Em main_v8.py, aumentar batch_size ou processar em chunks
test_loader_full = torch.utils.data.DataLoader(
    test_dataset_full,
    batch_size=16,  # Reduzir de 32 para 16
    shuffle=False
)
```

---

## ğŸ“ CHECKLIST DE VALIDAÃ‡ÃƒO

ApÃ³s executar o pipeline:

- [ ] Arquivo `best_model_v8.pt` criado
- [ ] Arquivo `apfd_per_build_FULL_testcsv.csv` criado
- [ ] Arquivo tem EXATAMENTE 278 linhas (277 + header)
- [ ] Mean APFD â‰¥ 0.55
- [ ] Log mostra "âœ… SUCCESS: Found exactly 277 builds"
- [ ] Todos os 4 arquivos CSV criados em results/
- [ ] NÃ£o hÃ¡ erros ou warnings crÃ­ticos no log
- [ ] Test F1 Macro â‰¥ 0.50
- [ ] Recall Fail â‰¥ 0.30
- [ ] Prediction Diversity â‰¥ 0.20

---

## ğŸ“ SUMÃRIO

âœ… **Pipeline Completo Implementado**:
- STEP 1-5: Treino e avaliaÃ§Ã£o no split test
- STEP 6: **Processamento FULL test.csv (277 builds)** â­ NOVO!

âœ… **Arquivos Principais Criados**:
- `apfd_per_build_FULL_testcsv.csv` (277 builds)
- `prioritized_test_cases_FULL_testcsv.csv` (31K test cases)

âœ… **ValidaÃ§Ãµes AutomÃ¡ticas**:
- Verifica 277 builds
- Valida colunas crÃ­ticas
- Confirma imputaÃ§Ã£o de features

âœ… **MÃ©trica Principal**: **Mean APFD** dos 277 builds

---

**Status**: âœ… **PRONTO PARA EXECUÃ‡ÃƒO**

**Comando**:
```bash
python main_v8.py --config configs/experiment_v8_fixed.yaml --device cuda
```

**DuraÃ§Ã£o**: 2-3 horas

**Resultado esperado**: Mean APFD â‰¥ 0.55 nos 277 builds do test.csv completo! ğŸš€
