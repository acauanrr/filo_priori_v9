# Filo-Priori V8 - Baseline Configuration
# Breaking the "Semantic Echo Chamber"
#
# Key Changes from V7:
# - Structural Stream: Uses historical features [6] instead of BGE embeddings [1024]
# - Graph Builder: Uses phylogenetic graphs (co-failure) instead of k-NN semantic
# - Architecture: Truly orthogonal information sources
#
# Step 2.4 Upgrade - Graph Attention Networks:
# - Structural Stream: Now uses GAT with multi-head attention instead of simple FFN
# - Unifies entire architecture under attention paradigm
# - Strengthens thesis: "Attention is superior to mean aggregation"

experiment:
  name: "v8_baseline"
  version: "8.0.0"
  description: "V8 baseline with true structural features and phylogenetic graphs"
  seed: 42

# Data Configuration
data:
  train_path: "datasets/train.csv"
  test_path: "datasets/test.csv"

  # Train/Val/Test split ratios
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42

  # Labeling strategy
  binary_classification: true
  binary_strategy: "pass_vs_all"
  binary_positive_class: "Pass"  # Class 1
  binary_negative_class: "Not-Pass"  # Class 0 (Fail/Delete/Blocked)

  # SMOTE (optional, usually disabled for V8)
  smote:
    enabled: false
    k_neighbors: 5
    sampling_strategy: "auto"

# Text Processing Configuration
text:
  num_commits_to_keep: 3
  max_commit_length: 512
  max_summary_length: 256
  max_steps_length: 512

# Semantic Embeddings (BGE-Large)
semantic:
  model_name: "models/finetuned_bge_v1"
  embedding_dim: 1024
  max_length: 512
  batch_size: 32
  pooling_strategy: "mean"  # BGE works best with mean pooling
  normalize_embeddings: true
  cache_path: "cache/embeddings"

  # Text fields to combine
  fields:
    - "TE_Summary"
    - "TC_Steps"
    - "commit"

# Structural Features (NEW in V8!)
structural:
  # Feature extraction
  extractor:
    recent_window: 5  # Window for recent_failure_rate
    min_history: 2    # Minimum executions for statistics
    cache_path: "cache/structural_features.pkl"

  # Features extracted (6 total):
  # 1. test_age
  # 2. failure_rate
  # 3. recent_failure_rate
  # 4. flakiness_rate
  # 5. commit_count
  # 6. test_novelty
  input_dim: 6

# Phylogenetic Graph (NEW in V8!)
# STEP 2.4: Graph is now REQUIRED for GAT-based StructuralStreamV8
graph:
  type: "co_failure"  # Options: 'co_failure', 'commit_dependency', 'hybrid'
  min_co_occurrences: 2
  weight_threshold: 0.1
  cache_path: "cache/phylogenetic_graph.pkl"

  # IMPORTANT: Graph is REQUIRED for GAT (Step 2.4)
  # GAT uses graph structure for attention-based aggregation
  build_graph: true

# Model Architecture (V8)
model:
  type: "dual_stream_v8"

  # Semantic Stream (processes text)
  semantic:
    input_dim: 1024  # BGE embedding dimension
    hidden_dim: 256
    num_layers: 2
    dropout: 0.3
    activation: "gelu"

  # Structural Stream (processes historical features with GAT)
  # STEP 2.4: Now uses Graph Attention Networks instead of FFN
  structural:
    input_dim: 6  # Historical features
    hidden_dim: 256
    num_heads: 4  # Multi-head attention for first GAT layer
    dropout: 0.3
    activation: "elu"  # ELU works well with GAT
    use_edge_weights: true  # Use phylogenetic graph edge weights

  # Fusion Layer
  fusion:
    type: "cross_attention"
    num_heads: 4
    dropout: 0.1

  # Classifier
  classifier:
    hidden_dims: [128, 64]
    dropout: 0.4

  num_classes: 2

# Training Configuration
training:
  num_epochs: 40
  batch_size: 32
  learning_rate: 5e-5
  weight_decay: 2e-4

  # Optimizer
  optimizer:
    type: "AdamW"
    betas: [0.9, 0.999]
    eps: 1e-8

  # Scheduler
  scheduler:
    type: "cosine"
    T_max: 40  # num_epochs
    eta_min: 1e-6

  # Gradient clipping
  grad_clip_norm: 1.0

  # Early stopping
  early_stopping:
    enabled: true
    patience: 12
    monitor: "val_f1_macro"
    mode: "max"

  # Mixed precision training
  use_amp: false

# Loss Function
loss:
  type: "focal"

  # Focal Loss parameters
  focal:
    alpha: [0.15, 0.85]  # [Not-Pass, Pass] - focus on minority class
    gamma: 2.0

  # Alternative: Weighted CE (for comparison)
  weighted_ce:
    use_class_weights: true

# Evaluation Configuration
evaluation:
  # Metrics to track
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision"
    - "recall"
    - "auprc"
    - "confusion_matrix"

  # Prediction calibration
  temperature_scaling:
    enabled: true
    initial_T: 1.0

  # Threshold search
  threshold_search:
    enabled: true
    search_range: [0.2, 0.8]
    search_step: 0.05
    metric: "f1_macro"

# APFD Configuration
apfd:
  # Build-level APFD calculation
  expected_builds: 277

  # Business rules
  count_tc_1_rule: true  # count_tc=1 → APFD=1.0
  only_fail_results: true  # Only builds with ≥1 'Fail'

  # Output
  save_prioritized_tests: true
  save_apfd_per_build: true

# Logging Configuration
logging:
  level: "INFO"
  log_to_file: true
  log_file: "logs/experiment_v8_baseline.log"
  log_to_tensorboard: true
  tensorboard_dir: "runs/experiment_v8_baseline"

  # Checkpointing
  checkpoint:
    save_best: true
    save_last: true
    save_every_n_epochs: 10

# Output Configuration
output:
  results_dir: "results/experiment_v8_baseline"
  save_predictions: true
  save_features: true  # Save extracted structural features
  save_confusion_matrix: true
  save_pr_curves: true

# Hardware Configuration
hardware:
  device: "cuda"  # 'cuda', 'cpu', or 'cuda:0'
  num_workers: 4
  pin_memory: true
