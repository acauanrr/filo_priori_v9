%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION: DISCUSSION (IEEE TSE Format)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section discusses the implications of our findings, analyzes the reasons
behind \filopriori{}'s effectiveness, and addresses practical considerations.

\subsection{Why Does Multi-Edge Graph Construction Matter?}

The ablation study reveals that the Dense Multi-Edge Graph contributes +10.0\%
to performance, making it the most critical component. We attribute this to
several factors:

\textbf{Capturing Test Dependencies}: The multi-edge graph encodes relationships
that simple features cannot capture. Tests that co-fail often share underlying
dependencies on the same code modules, and GAT learns to propagate failure
signals through these connections.

\textbf{Dynamic Attention}: Unlike standard GAT, GATv2~\cite{brody2022attentive}
computes dynamic attention that depends on both query and key nodes. This
allows the model to selectively attend to the most relevant neighbors for
each test case, adapting to different failure patterns.

\textbf{Multi-Edge Information}: Our multi-edge graph combines co-failure,
co-success, and semantic edges. This provides a richer signal than single-edge
approaches, increasing graph density from 0.02\% to 0.5-1.0\%.

\subsection{The Role of Weighted Focal Loss}

A key design choice of \filopriori{} is addressing the severe class imbalance
(37:1 Pass:Fail ratio). Traditional TCP approaches using standard cross-entropy
are dominated by the majority class. Our Weighted Focal Loss addresses this:

\begin{equation}
    \mathcal{L} = -\alpha \cdot w_t \cdot (1 - p_t)^\gamma \cdot \log(p_t)
\end{equation}

The sensitivity analysis shows that the choice of loss function has a 4.7\%
impact on performance, with Weighted Focal Loss achieving the best results.
Additionally, the ablation study reveals that proper balancing strategy
(Single Balancing) contributes +4.0\%. This validates our hypothesis that
careful handling of class imbalance is critical for TCP.

\subsection{Comparison with FailureRate Baseline}

\filopriori{} outperforms the FailureRate heuristic by 1.4\%, though not
statistically significant ($p = 0.363$). This raises an important question:
\emph{When is a deep learning approach preferable to simple heuristics?}

We observe that \filopriori{} provides advantages in:
\begin{itemize}
    \item \textbf{New test cases}: Tests without history benefit from semantic
    similarity to known failing tests.
    \item \textbf{Changing patterns}: The model adapts to evolving failure
    patterns through the graph structure.
    \item \textbf{Complex dependencies}: The GNN captures multi-hop relationships
    that simple heuristics miss.
\end{itemize}

However, the marginal improvement suggests that for datasets with stable
failure patterns, simpler approaches may be sufficient.

\subsection{Practical Implications}

\textbf{For Practitioners}: \filopriori{} can be integrated into CI/CD pipelines
to prioritize test execution. The 51.9\% improvement over random ordering
translates to substantially faster fault detection, reducing the feedback loop for developers.

\textbf{Computational Cost}: Training requires approximately 2-3 hours on a
single GPU. Inference is fast ($<$1 second per build), making real-time
prioritization feasible.

\textbf{Data Requirements}: The approach requires historical test execution
data with at least 50 builds for effective graph construction. Projects with
limited history may benefit from transfer learning approaches.

\subsection{Lessons Learned}

\begin{enumerate}
    \item \textbf{Graph structure matters}: Modeling test relationships through
    graphs provides substantial benefits over treating tests independently.

    \item \textbf{Simple architectures suffice}: 1-layer GNN with 2 heads
    outperformed deeper architectures, suggesting that test relationships
    can be captured with shallow networks.

    \item \textbf{Feature selection is important}: 10 carefully selected features
    outperformed 29 features, indicating that noise reduction improves
    generalization.

    \item \textbf{Address class imbalance}: Weighted Focal Loss is essential
    for handling the extreme class imbalance in test execution data.
\end{enumerate}

\subsection{Limitations}

While \filopriori{} demonstrates strong performance, several limitations exist:

\begin{itemize}
    \item \textbf{Domain specificity}: While we evaluated on three distinct
    domains (industrial testing, GNN benchmarks, and open-source CI/CD),
    results may not generalize to all software projects or testing contexts.

    \item \textbf{Cold start}: New test cases without semantic similarity to
    existing tests may not benefit from the graph structure.

    \item \textbf{Graph construction overhead}: Building the test relationship graph
    adds preprocessing time, though this is amortized over multiple predictions.

    \item \textbf{Interpretability}: While ablation studies provide component-level
    insights, individual predictions remain difficult to explain.
\end{itemize}
