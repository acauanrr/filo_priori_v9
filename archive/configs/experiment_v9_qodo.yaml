# Filo-Priori V9 - Qodo-Embed-1-1.5B with Separate TC and Commit Encodings
#
# MAJOR CHANGES FROM V8:
# - Embedding model: BGE → Qodo-Embed-1-1.5B
# - Embedding dimension: 1024 → 3072 (1536 for TCs + 1536 for Commits)
# - Separate encoding: TCs (summary+steps) and Commits (preprocessed) encoded separately
# - NO fine-tuning: Using pre-trained Qodo model directly
# - Removed BGE-specific configurations

experiment:
  name: "v9_qodo"
  version: "9.0.0"
  description: "V9 with Qodo-Embed-1-1.5B - separate TC and Commit encodings"
  seed: 42

# Data Configuration
data:
  train_path: "datasets/train.csv"
  test_path: "datasets/test.csv"

  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42

  binary_classification: true
  binary_strategy: "pass_vs_fail"
  binary_positive_class: "Pass"
  binary_negative_class: "Fail"

  smote:
    enabled: false

# Text Processing
text:
  num_commits_to_keep: 5  # Increased for better commit context
  max_commit_length: 1024  # Qodo supports up to 32k tokens
  max_summary_length: 512
  max_steps_length: 1024

# Commit Extraction (NEW in V9)
commit:
  max_commits_per_tc: 10
  include_commit_metadata: true  # Include author, files changed, etc.

# Semantic Embeddings with Qodo-Embed (NEW in V9)
semantic:
  model_name: "Qodo/Qodo-Embed-1-1.5B"
  embedding_dim: 1536  # Single embedding dimension
  combined_embedding_dim: 3072  # TC (1536) + Commit (1536)
  max_length: 512  # Per field
  batch_size: 32
  normalize_embeddings: true
  cache_path: "cache/embeddings_qodo"

  # Separate encoding (NEW in V9)
  separate_encoding: true
  encode_tc_separately: true
  encode_commit_separately: true

# Structural Features (UNCHANGED from V8)
structural:
  extractor:
    recent_window: 5
    min_history: 2
    cache_path: "cache/structural_features.pkl"
  input_dim: 6

# Phylogenetic Graph (UNCHANGED from V8)
graph:
  type: "co_failure"
  min_co_occurrences: 2
  weight_threshold: 0.1
  cache_path: "cache/phylogenetic_graph.pkl"
  build_graph: true

# Model Architecture - ADAPTED FOR 3072 EMBEDDING DIM
model:
  type: "dual_stream_v9"

  semantic:
    input_dim: 3072  # TC (1536) + Commit (1536)
    hidden_dim: 256
    num_layers: 2
    dropout: 0.15
    activation: "gelu"

  structural:
    input_dim: 6
    hidden_dim: 256
    num_heads: 4
    dropout: 0.15
    activation: "elu"
    use_edge_weights: true

  fusion:
    type: "cross_attention"
    num_heads: 4
    dropout: 0.1

  classifier:
    hidden_dims: [128, 64]
    dropout: 0.25

  num_classes: 2

# Training
training:
  num_epochs: 50
  batch_size: 32
  learning_rate: 7.5e-5
  weight_decay: 3e-5

  optimizer:
    type: "AdamW"
    betas: [0.9, 0.999]
    eps: 1e-8

  scheduler:
    type: "cosine"
    T_max: 50
    eta_min: 1e-6

  grad_clip_norm: 1.0

  early_stopping:
    enabled: true
    patience: 20
    monitor: "val_f1_macro"
    mode: "max"
    min_delta: 0.001

  use_amp: false

# Loss
loss:
  type: "weighted_ce"

  weighted_ce:
    use_class_weights: false
    class_weights: [60.0, 1.0]
    label_smoothing: 0.0

# Evaluation
evaluation:
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision"
    - "recall"
    - "auprc"
    - "confusion_matrix"
    - "prediction_diversity"

  temperature_scaling:
    enabled: true
    initial_T: 1.0

  threshold_search:
    enabled: true
    search_range: [0.10, 0.60]
    search_step: 0.05
    metric: "f1_macro"

# APFD
apfd:
  expected_builds: 277
  count_tc_1_rule: true
  only_fail_results: true
  save_prioritized_tests: true
  save_apfd_per_build: true

# Logging
logging:
  level: "INFO"
  log_to_file: true
  log_file: "logs/experiment_v9_qodo.log"
  log_to_tensorboard: true
  tensorboard_dir: "runs/experiment_v9_qodo"

  checkpoint:
    save_best: true
    save_last: true
    save_every_n_epochs: 10

# Output
output:
  results_dir: "results/experiment_v9_qodo"
  save_predictions: true
  save_features: true
  save_confusion_matrix: true
  save_pr_curves: true

# Hardware
hardware:
  device: "cuda"
  num_workers: 4
  pin_memory: true

# ============================================================================
# EXPECTED IMPROVEMENTS IN V9:
# ============================================================================
# MOTIVATION:
# - V8 fine-tuned BGE showed degraded performance (APFD: 0.5967 → 0.5481)
# - Fine-tuning may have caused overfitting or degraded general representations
#
# KEY CHANGES:
# 1. Qodo-Embed-1-1.5B: State-of-art embedding model (1.5B params vs BGE's 335M)
# 2. Separate Encodings: TCs and Commits encoded independently
#    - Preserves semantic structure of each information type
#    - Doubles embedding dimension: 1024 → 3072 (more capacity)
# 3. No Fine-tuning: Uses pre-trained model directly
#    - Avoids overfitting risk
#    - Leverages general-purpose representations
#
# EXPECTED METRICS:
# - Mean APFD: 0.5481 → 0.60+ (improvement over V8)
# - Test F1 Macro: 0.5360 → 0.55+
# - Better separation between TC and Commit information
# - More stable training (no fine-tuning instability)
#
# SUCCESS CRITERIA:
# - Mean APFD > 0.58 (better than V8 and V8_improved)
# - Test F1 Macro > 0.54
# - Recall Fail ≥ 20%
# - No catastrophic collapse
#
# VALIDATION:
# python main_v9.py --config configs/experiment_v9_qodo.yaml --device cuda
# ============================================================================
