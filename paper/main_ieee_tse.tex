%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FILO-PRIORI V9 - IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Target: IEEE Transactions on Software Engineering (IEEE TSE)
% Template: IEEEtran (IEEE Computer Society Transactions)
%
% Structure:
%   - sections/introduction.tex
%   - sections/background.tex
%   - sections/related_work.tex
%   - sections/approach.tex
%   - sections/experimental_design.tex
%   - sections/results.tex
%   - sections/discussion.tex
%   - sections/threats.tex
%   - sections/conclusion.tex
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[10pt,journal,compsoc]{IEEEtran}

%------------------------------------------------------------------------------
% PACKAGES
%------------------------------------------------------------------------------
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{url}
\usepackage{hyperref}
\usepackage{balance}

% For code listings
\usepackage{listings}
\lstset{
  basicstyle=\footnotesize\ttfamily,
  breaklines=true,
  frame=single
}

% For subfigures
\usepackage{subcaption}

% For table notes
\usepackage{threeparttable}

% For colored boxes (findings summary)
\usepackage[most]{tcolorbox}

%------------------------------------------------------------------------------
% CUSTOM COMMANDS
%------------------------------------------------------------------------------
\newcommand{\filopriori}{\textsc{Filo-Priori}}
\newcommand{\apfd}{\textsc{APFD}}
\newcommand{\gatv}{GATv2}

% Highlight for revision
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\rev}[1]{\textcolor{blue}{#1}}

%------------------------------------------------------------------------------
% DOCUMENT START
%------------------------------------------------------------------------------
\begin{document}

%------------------------------------------------------------------------------
% TITLE
%------------------------------------------------------------------------------
\title{Filo-Priori: A Phylogenetic Approach to Test Case Prioritization\\Using Evolutionary Graph Neural Networks}

%------------------------------------------------------------------------------
% AUTHORS
%------------------------------------------------------------------------------
\author{
  \IEEEauthorblockN{Acauan C. Ribeiro}
  \IEEEauthorblockA{
    Instituto de Computa\c{c}\~{a}o (IComp)\\
    Universidade Federal do Amazonas (UFAM)\\
    Manaus, AM, Brazil\\
    acauan@icomp.ufam.edu.br
  }
}

%------------------------------------------------------------------------------
% HEADERS
%------------------------------------------------------------------------------
\markboth{IEEE Transactions on Software Engineering, Vol. XX, No. X, Month 2026}%
{Ribeiro: Filo-Priori: Deep Learning-based Test Case Prioritization}

%------------------------------------------------------------------------------
% ABSTRACT
%------------------------------------------------------------------------------
\IEEEtitleabstractindextext{%
\begin{abstract}
Test Case Prioritization (TCP) aims to order test cases to maximize early fault
detection in Continuous Integration (CI) environments. Existing approaches treat
software versions as linear time series, failing to capture the complex branching
and merging patterns that characterize real-world development. We propose a paradigm
shift: treating software evolution as a \textbf{phylogenetic tree}, where commits
represent taxa and the Git DAG captures evolutionary relationships.

We present \filopriori{}, a bio-inspired deep learning approach that introduces:
(1) a \textbf{Phylogenetic Graph} that respects the topology of the Git DAG,
encoding evolutionary distances between commits; (2) a \textbf{Phylo-Encoder}
using Gated Graph Neural Networks (GGNN) to propagate failure signals through
evolutionary history; (3) \textbf{Hierarchical Attention} at micro (code), meso
(call graph), and macro (history) levels; and (4) \textbf{Ranking-Aware Training}
combining Focal Loss with RankNet-style pairwise loss aligned with APFD.

We evaluate \filopriori{} on an industrial dataset containing 277 builds with
failing tests and 52,102 test executions. Results show a mean APFD of 0.6413,
representing 14.6\% improvement over random ordering ($p < 0.001$) and 2.0\%
over the strongest baseline. Ablation reveals Graph Attention contributes +17.0\%
to performance. Temporal validation confirms robustness (APFD: 0.619--0.663).

This work introduces the phylogenetic metaphor to TCP, providing a principled
framework for modeling software evolution. Our replication package is publicly available.
\end{abstract}

%------------------------------------------------------------------------------
% KEYWORDS
%------------------------------------------------------------------------------
\begin{IEEEkeywords}
Test Case Prioritization, Phylogenetic Analysis, Software Evolution, Graph Neural Networks,
Git DAG, Continuous Integration, Hierarchical Attention, Ranking-Aware Learning
\end{IEEEkeywords}
}

\maketitle

%------------------------------------------------------------------------------
% SECTION 1: INTRODUCTION
%------------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}
\IEEEPARstart{C}{ontinuous} Integration (CI) has become a fundamental practice
in modern software development, enabling teams to integrate code changes frequently
and detect defects early~\cite{hilton2016usage, fowler2006continuous}. A key
challenge in CI environments is managing the growing test suite: as software
evolves, the number of test cases increases, making it impractical to execute
all tests for every commit~\cite{memon2017taming}.

Test Case Prioritization (TCP) addresses this challenge by ordering test cases
to maximize early fault detection~\cite{rothermel2001prioritizing, elbaum2002test}.
The goal is to execute tests most likely to fail first, providing faster feedback
to developers. The effectiveness of TCP is typically measured using the Average
Percentage of Faults Detected (APFD) metric~\cite{rothermel1999test}.

\textbf{The Problem with Linear History.} Existing TCP approaches, whether based
on coverage~\cite{rothermel2001prioritizing}, historical failure~\cite{kim2002history},
or machine learning~\cite{spieker2017reinforcement, pan2022test}, share a common
limitation: they treat software history as a \emph{linear time series}. This
assumption ignores the rich branching and merging structure inherent in version
control systems like Git, where development proceeds through parallel branches,
feature branches, and merge commits~\cite{german2009evolution}.

\textbf{A Paradigm Shift: The Phylogenetic Metaphor.} We propose a fundamental
reconceptualization of software evolution, drawing inspiration from computational
phylogenetics in biology~\cite{felsenstein2004phylogenetics}. In phylogenetics,
species (taxa) evolve through branching processes captured by phylogenetic trees.
We observe a striking parallel: software versions (commits) evolve through
branching processes captured by the Git Directed Acyclic Graph (DAG).

Table~\ref{tab:phylo_mapping} presents our conceptual mapping between biological
and software engineering domains:

\begin{table}[h]
\centering
\caption{Mapping from Biology to Software Engineering}
\label{tab:phylo_mapping}
\begin{tabular}{ll}
\toprule
\textbf{Biology Concept} & \textbf{Software Engineering} \\
\midrule
Taxon/Species & Commit/Version \\
DNA Sequence & Source Code / AST \\
Mutation (SNP) & Code Diff \\
Phylogenetic Tree & Git DAG \\
Phylogenetic Signal & Failure Autocorrelation \\
Common Ancestor & Merge Base \\
\bottomrule
\end{tabular}
\end{table}

This metaphor is not merely linguistic---it provides a principled mathematical
framework. Just as phylogenetic signals (trait similarities due to shared ancestry)
inform biological predictions, \emph{software phylogenetic signals} (failure
patterns inherited from ancestral commits) can inform test prioritization.

In this paper, we present \filopriori{}, a bio-inspired deep learning approach for
Test Case Prioritization that operationalizes this metaphor through four key innovations:

\begin{enumerate}
    \item \textbf{Phylogenetic Graph Representation}: We construct a graph that
    respects the Git DAG topology, computing phylogenetic distances between commits
    based on shortest paths and merge complexity. This captures the evolutionary
    context that linear approaches ignore~\cite{godfrey2005evolution}.

    \item \textbf{Phylo-Encoder (GGNN Temporal)}: We employ a Gated Graph Neural
    Network~\cite{li2016gated} to propagate information from ancestral commits to
    descendants, weighted by phylogenetic distance. This mimics how traits propagate
    through evolutionary trees in phylogenetics~\cite{felsenstein2004phylogenetics}.

    \item \textbf{Hierarchical Attention Mechanism}: We introduce attention at three
    levels: \emph{micro} (code tokens), \emph{meso} (call graph structure), and
    \emph{macro} (commit history). This multi-scale approach captures dependencies
    from fine-grained code to high-level evolutionary patterns.

    \item \textbf{Ranking-Aware Training}: We combine Focal Loss~\cite{lin2017focal}
    for class imbalance with RankNet-style pairwise loss~\cite{burges2005learning}
    aligned with APFD, plus a novel \emph{phylogenetic regularization} term that
    penalizes predictions inconsistent with evolutionary structure.
\end{enumerate}

We evaluate \filopriori{} on an industrial dataset containing 277 builds with
at least one failing test, totaling 52,102 test executions from 2,347 unique
test cases. Our evaluation addresses four research questions:

\begin{itemize}
    \item \textbf{RQ1}: How effective is \filopriori{} compared to baseline methods?
    \item \textbf{RQ2}: What is the contribution of each architectural component?
    \item \textbf{RQ3}: How robust is \filopriori{} across different time periods?
    \item \textbf{RQ4}: How sensitive is \filopriori{} to hyperparameter choices?
\end{itemize}

Our results show that \filopriori{} achieves a mean APFD of 0.6413, significantly
outperforming random ordering by 14.6\% ($p < 0.001$) and the strongest baseline
(FailureRate) by 2.0\%. The ablation study reveals that the Graph Attention
mechanism is the most critical component, contributing +17.0\% to performance.

\textbf{Contributions.} This paper makes the following contributions:
\begin{itemize}
    \item \textbf{Conceptual}: We introduce the phylogenetic metaphor to TCP,
    providing a principled framework for modeling software evolution that
    respects the Git DAG topology.
    \item \textbf{Architectural}: We propose a novel neural architecture combining
    Phylo-Encoder (GGNN), Code-Encoder (GATv2), and Hierarchical Attention for
    multi-scale feature fusion.
    \item \textbf{Methodological}: We define the \emph{phylogenetic distance kernel}
    for computing evolutionary distances and introduce phylogenetic regularization
    in the loss function.
    \item \textbf{Empirical}: We demonstrate effectiveness on an industrial dataset,
    achieving 14.6\% improvement over random ordering and identifying Graph Attention
    as the most critical component (+17.0\% contribution).
    \item \textbf{Practical}: We provide a complete replication package enabling
    reproducibility and extension of our approach.
\end{itemize}

\textbf{Paper Organization.} Section~\ref{sec:background} presents background
concepts. Section~\ref{sec:related} discusses related work. Section~\ref{sec:approach}
describes our approach. Section~\ref{sec:experimental} presents the experimental
design. Section~\ref{sec:results} reports results. Section~\ref{sec:discussion}
discusses findings. Section~\ref{sec:threats} addresses threats to validity.
Section~\ref{sec:conclusion} concludes.

%------------------------------------------------------------------------------
% SECTION 2: BACKGROUND
%------------------------------------------------------------------------------
\section{Background}
\label{sec:background}

This section introduces fundamental concepts underlying our approach.

\subsection{Test Case Prioritization}
\label{sec:bg_tcp}

Test Case Prioritization (TCP) is the process of ordering test cases for execution
to achieve certain objectives, such as maximizing early fault detection~\cite{rothermel2001prioritizing}.
Formally, given a test suite $T$ and a permutation function $PT$ that produces
ordered sequences of $T$, TCP aims to find an optimal ordering $T' \in PT$ that
maximizes a given objective function~\cite{elbaum2002test}.

In Continuous Integration environments, TCP is particularly important because:
(1) test suites grow over time, making exhaustive testing impractical~\cite{memon2017taming},
(2) developers need rapid feedback on code changes~\cite{hilton2016usage}, and
(3) computing resources for testing are often limited~\cite{spieker2017reinforcement}.

\subsection{APFD Metric}
\label{sec:bg_apfd}

The Average Percentage of Faults Detected (APFD) is the standard metric for
evaluating TCP effectiveness~\cite{rothermel1999test}. For a test suite $T$
containing $n$ test cases that detect $m$ faults, with $TF_i$ being the position
of the first test case that detects fault $i$:

\begin{equation}
    \text{APFD} = 1 - \frac{\sum_{i=1}^{m} TF_i}{n \times m} + \frac{1}{2n}
\end{equation}

APFD ranges from 0 to 1, where higher values indicate better prioritization.
An APFD of 0.5 corresponds to random ordering, while 1.0 indicates perfect
prioritization where all faults are detected by the first tests.

\subsection{Graph Attention Networks}
\label{sec:bg_gat}

Graph Attention Networks (GAT)~\cite{velickovic2018graph} extend Graph Neural
Networks by incorporating attention mechanisms to weigh the importance of
neighboring nodes. For a node $i$ with neighbors $\mathcal{N}_i$, GAT computes:

\begin{equation}
    \vec{h}_i' = \sigma\left(\sum_{j \in \mathcal{N}_i} \alpha_{ij} \mathbf{W} \vec{h}_j\right)
\end{equation}

where $\alpha_{ij}$ are attention coefficients computed as:

\begin{equation}
    \alpha_{ij} = \text{softmax}_j\left(\text{LeakyReLU}\left(\vec{a}^T[\mathbf{W}\vec{h}_i \| \mathbf{W}\vec{h}_j]\right)\right)
\end{equation}

Brody et al.~\cite{brody2022attentive} showed that standard GAT computes a
restricted form of ``static'' attention where the ranking of attention scores
is independent of the query node. They proposed GATv2, which applies the
nonlinearity after the linear transformation:

\begin{equation}
    \alpha_{ij} = \text{softmax}_j\left(\vec{a}^T \cdot \text{LeakyReLU}\left(\mathbf{W}[\vec{h}_i \| \vec{h}_j]\right)\right)
\end{equation}

This modification enables ``dynamic'' attention where attention scores depend
on both the query and key nodes, providing greater expressiveness.

\subsection{Computational Phylogenetics}
\label{sec:bg_phylo}

Phylogenetics is the study of evolutionary relationships among organisms based
on molecular sequences~\cite{felsenstein2004phylogenetics}. Key concepts include:

\textbf{Phylogenetic Trees}: Branching diagrams representing evolutionary
relationships, where internal nodes represent ancestral species and leaf nodes
represent extant species (taxa).

\textbf{Phylogenetic Distance}: The evolutionary distance between two taxa,
typically computed as the path length in the tree, often weighted by branch
lengths representing time or mutation rates.

\textbf{Phylogenetic Signal}: The tendency for related species to resemble each
other more than random species. Statistically, this represents autocorrelation
in traits due to shared ancestry.

In software engineering, we observe analogous structures:
\begin{itemize}
    \item The \textbf{Git DAG} is a phylogenetic tree where commits are taxa
    \item \textbf{Code diffs} are mutations between ancestral and descendant code
    \item \textbf{Failure patterns} exhibit phylogenetic signal---tests that fail
    in parent commits often fail in child commits
\end{itemize}

This parallel motivates our approach: we apply phylogenetic distance kernels
to weight information propagation through the Git history graph.

\subsection{Learning to Rank}
\label{sec:bg_ltr}

Learning to Rank (LTR) is a family of machine learning techniques for optimizing
ranking functions~\cite{liu2009learning}. LTR approaches are categorized as:
\begin{itemize}
    \item \textbf{Pointwise}: Treat ranking as classification or regression on individual items.
    \item \textbf{Pairwise}: Optimize the relative ordering of item pairs.
    \item \textbf{Listwise}: Directly optimize list-level metrics.
\end{itemize}

RankNet~\cite{burges2005learning} is a pairwise approach that uses a neural
network to learn a scoring function. For two items $i$ and $j$ with scores
$s_i$ and $s_j$, the probability that $i$ should be ranked higher than $j$ is:

\begin{equation}
    P_{ij} = \frac{1}{1 + e^{-\sigma(s_i - s_j)}}
\end{equation}

The loss function is the cross-entropy between predicted and true probabilities.

%------------------------------------------------------------------------------
% SECTION 3: RELATED WORK
%------------------------------------------------------------------------------
\section{Related Work}
\label{sec:related}

We conducted a systematic literature review following the guidelines of
Kitchenham and Charters~\cite{kitchenham2007guidelines}. Our search targeted
IEEE Xplore and ACM Digital Library using the query: \texttt{(Test Case
Prioritization OR Regression Testing) AND (Graph Neural Network OR Deep Learning
OR Software Evolution)}. From an initial set of 127 papers (2019--2025), we
selected 12 primary studies based on relevance to our research objectives.
Table~\ref{tab:rsl_studies} summarizes these studies across three themes:
(1) GNNs for software engineering, (2) deep learning for TCP, and
(3) software evolution analysis.

\input{tables/tab_rsl_studies}

\subsection{Traditional TCP Approaches}

Early TCP research focused on code coverage-based techniques. Rothermel et al.~\cite{rothermel2001prioritizing}
proposed total and additional coverage prioritization, while Elbaum et al.~\cite{elbaum2002test}
conducted extensive empirical studies comparing different strategies.

History-based approaches leverage past test execution results. Kim and Porter~\cite{kim2002history}
proposed using historical failure information, showing that tests that failed
recently are more likely to fail again. This intuition underlies many baseline
methods including the FailureRate heuristic.

\subsection{Machine Learning for TCP}

Machine learning has been increasingly applied to TCP. Spieker et al.~\cite{spieker2017reinforcement}
introduced RETECS, using reinforcement learning for TCP in CI environments.
Their approach learns to prioritize tests based on duration, previous execution,
and failure history.

Bertolino et al.~\cite{bertolino2020learning} compared learning-to-rank and
ranking-to-learn strategies, demonstrating the importance of aligning training
objectives with evaluation metrics.

Bagherzadeh et al.~\cite{bagherzadeh2022reinforcement} extended reinforcement
learning approaches with improved reward functions and demonstrated effectiveness
on industrial datasets.

\subsection{Deep Learning for TCP}

Deep learning approaches have shown promising results. Pan et al.~\cite{pan2022test}
used neural networks to learn test case representations from historical data.
Chen et al.~\cite{chen2023deeporder} proposed DeepOrder, using deep neural
networks for TCP in CI environments.

TCP-Net~\cite{abdelkarim2022tcp} introduced an end-to-end deep neural network
approach that learns directly from test execution data. Recent work by
Khan et al.~\cite{khan2024hyperparameter} demonstrated the importance of
hyperparameter optimization in ML-based TCP.

\subsection{Graph Neural Networks in Software Engineering}

GNNs have been applied to various software engineering tasks.
Allamanis et al.~\cite{allamanis2018learning} used GNNs for program representation.
In testing, GraphPrior~\cite{wang2023graphprior} applied GNNs for test input
prioritization in DNN testing. Lou et al.~\cite{lou2024towards} applied GNNs
to fault localization with enhanced code representations.

For temporal graphs, Rossi et al.~\cite{rossi2020temporal} proposed Temporal
Graph Networks for dynamic graphs, and Xu et al.~\cite{xu2020inductive} introduced
inductive methods for temporal representations.

\subsection{Software Evolution Analysis}

Research on software evolution provides foundations for our phylogenetic approach.
German et al.~\cite{german2009evolution} introduced change impact graphs for
analyzing the effects of prior code changes. Godfrey and Zou~\cite{godfrey2005evolution}
developed origin analysis for detecting entity evolution across versions.
Dig and Johnson~\cite{dig2006automated} automated detection of refactorings in
evolving components.

Recent work on code intelligence~\cite{niu2024deeplearning, feng2020codebert,
guo2021graphcodebert} provides semantic understanding of code that complements
evolutionary analysis. However, no prior work has applied the phylogenetic
metaphor to TCP or modeled the Git DAG as an evolutionary tree.

\subsection{Comparison with Our Approach}

\filopriori{} differs from prior work in several key aspects (Table~\ref{tab:comparison}):

\begin{table}[h]
\centering
\caption{Comparison with Related Approaches}
\label{tab:comparison}
\begin{tabular}{lccc}
\toprule
\textbf{Approach} & \textbf{Git DAG} & \textbf{GNN} & \textbf{Ranking} \\
\midrule
RETECS~\cite{spieker2017reinforcement} & No & No & RL \\
DeepOrder~\cite{chen2023deeporder} & No & No & DL \\
NodeRank~\cite{vansoest2024noderank} & No & Yes & Heuristic \\
GraphPrior~\cite{wang2023graphprior} & No & Yes & Mutation \\
\textbf{\filopriori{}} & \textbf{Yes} & \textbf{Yes} & \textbf{LTR} \\
\bottomrule
\end{tabular}
\end{table}

Key differentiators:
\begin{itemize}
    \item \textbf{Phylogenetic modeling}: We are the first to treat the Git DAG
    as a phylogenetic tree, enabling principled distance-weighted propagation.
    \item \textbf{Hierarchical attention}: We introduce multi-scale attention
    (micro/meso/macro) not found in prior TCP approaches.
    \item \textbf{Evolutionary regularization}: Our loss function includes a
    phylogenetic regularization term penalizing predictions inconsistent with
    evolutionary structure.
\end{itemize}

%------------------------------------------------------------------------------
% SECTION 4: APPROACH
%------------------------------------------------------------------------------
\section{Approach: \filopriori{}}
\label{sec:approach}

This section describes the \filopriori{} approach for Test Case Prioritization.
Figure~\ref{fig:architecture} provides an overview of the architecture.

\subsection{Overview}

Figure~\ref{fig:architecture} presents the \filopriori{} architecture. The system
takes as input: (1) the Git DAG with commit metadata, (2) source code and test
descriptions, and (3) historical test execution results. It outputs a ranking
of test cases by predicted failure probability.

The approach consists of three main modules in a \textbf{hybrid architecture}:
\begin{enumerate}
    \item \textbf{Phylo-Encoder LITE}: A lightweight GGNN-based encoder (2 layers,
    128-dim) that processes the Git DAG, computing phylogenetic distances with
    a learnable temperature parameter and propagating failure signals through
    evolutionary history.
    \item \textbf{Code-Encoder}: A GATv2-based encoder that processes the test
    relationship graph, capturing co-failure and semantic dependencies between tests.
    \item \textbf{Cross-Attention Fusion}: Combines Phylo-Encoder outputs with
    GATv2 structural features via element-wise addition, then fuses with semantic
    features through cross-attention for final classification.
\end{enumerate}

This hybrid design balances scientific novelty (phylogenetic encoding) with
proven performance (GATv2), achieving better results than either approach alone.

\subsection{Semantic Feature Extraction}

We use Sentence-BERT (SBERT)~\cite{reimers2019sentence} with the \texttt{all-mpnet-base-v2}
model to encode textual information. For each test case, we concatenate:
\begin{itemize}
    \item Test case summary (TC\_Summary)
    \item Test case steps (TC\_Steps)
\end{itemize}

For each commit, we encode:
\begin{itemize}
    \item Commit message
    \item Code diff (truncated to 2000 characters)
\end{itemize}

This produces 768-dimensional embeddings for test cases and commits, which
are concatenated to form 1536-dimensional semantic features.

\subsection{Structural Feature Extraction}

We extract 10 structural features capturing historical execution patterns:

\begin{enumerate}
    \item \textbf{test\_age}: Number of builds since first appearance
    \item \textbf{failure\_rate}: Historical failure percentage
    \item \textbf{recent\_failure\_rate}: Failure rate in last 5 builds
    \item \textbf{flakiness\_rate}: Pass/fail oscillation frequency
    \item \textbf{commit\_count}: Number of associated commits
    \item \textbf{test\_novelty}: Binary flag for first appearance
    \item \textbf{consecutive\_failures}: Current failure streak
    \item \textbf{max\_consecutive\_failures}: Maximum observed streak
    \item \textbf{failure\_trend}: Trend analysis (-1/0/+1)
    \item \textbf{cr\_count}: Associated change request count
\end{enumerate}

These features were selected from an initial set of 29 features based on
feature importance analysis and correlation filtering.

\subsection{Phylogenetic Graph Construction}

We construct two complementary graphs:

\textbf{Commit Graph (Git DAG)}: Nodes represent commits, edges represent
parent-child relationships from the Git history. For a commit $c_{curr}$ and
its $k$ ancestors, we extract a subgraph preserving the DAG topology.

\textbf{Phylogenetic Distance Kernel}: We compute evolutionary distance as:
\begin{equation}
    d_{phylo}(c_i, c_j) = \text{shortest\_path}(c_i, c_j) \times \beta^{n_{merges}}
\end{equation}
where $n_{merges}$ is the number of merge commits on the path and $\beta = 0.9$
is a decay factor. This captures the intuition that merges represent
evolutionary synchronization points that reset divergence.

\textbf{Test Relationship Graph}: Nodes represent test cases, with three edge types:
\begin{enumerate}
    \item \textbf{Co-Failure Edges} (weight 1.0): Connect tests that fail
    together, capturing fault-related dependencies.
    \item \textbf{Co-Success Edges} (weight 0.5): Connect tests that pass
    together, capturing functional similarity.
    \item \textbf{Semantic Edges} (weight 0.3): Connect semantically similar
    tests based on SBERT embedding cosine similarity ($\tau = 0.75$).
\end{enumerate}

This multi-edge approach increases graph density from 0.02\% to 0.5-1.0\%.

\subsection{Phylo-Encoder LITE}

The Phylo-Encoder LITE is a lightweight GGNN-based encoder (2 layers, 128-dim)
that learns representations from the Git DAG using a Gated Graph Neural
Network~\cite{li2016gated}:

\begin{equation}
    h_c^{(t)} = \text{GRU}\left(h_c^{(t-1)}, \sum_{c' \in \mathcal{N}(c)} w_{phylo}(c, c') \cdot h_{c'}^{(t-1)}\right)
\end{equation}

where $w_{phylo}(c, c') = \exp(-d_{phylo}(c, c') / \tau)$ are phylogenetic weights
with \textbf{learnable temperature} $\tau$. This allows the model to adaptively
control the influence of phylogenetic distance during training.

The key innovation is the \textbf{Phylogenetic Distance Kernel} with learnable
temperature, which enables failure information to propagate from ancestors to
descendants weighted by evolutionary distance. Closer commits in the DAG have
stronger influence, capturing the intuition that related code changes exhibit
similar failure patterns.

For commit messages, we use SBERT~\cite{reimers2019sentence} to obtain semantic
embeddings (768-dim), which are projected to 128-dim as initial node features $h_c^{(0)}$.

\subsection{Code-Encoder (GATv2)}

The Code-Encoder processes the test relationship graph using GATv2~\cite{brody2022attentive}:

\textbf{Input}: Semantic embeddings (768-dim from SBERT) concatenated with
structural features (10-dim), projected to 128 dimensions.

\textbf{GATv2 Layer}: We use dynamic attention~\cite{brody2022attentive}:
\begin{equation}
    \alpha_{ij} = \text{softmax}_j\left(\vec{a}^T \cdot \text{LeakyReLU}\left(\mathbf{W}[\vec{h}_i \| \vec{h}_j]\right)\right)
\end{equation}

With 2 attention heads, the output is 64-dimensional per test case.

\subsection{Hybrid Fusion Architecture}

The hybrid architecture combines phylogenetic and structural features through
a two-stage fusion process:

\textbf{Stage 1: Phylo-Structural Combination}. The Phylo-Encoder outputs
($h_{phylo} \in \mathbb{R}^{128}$) are first projected to match the GATv2
output dimension:
\begin{equation}
    h_{phylo}' = \text{LayerNorm}(\text{GELU}(W_{proj} \cdot h_{phylo}))
\end{equation}
where $W_{proj} \in \mathbb{R}^{256 \times 128}$. Then, phylo and structural
features are combined via element-wise addition:
\begin{equation}
    h_{combined} = h_{structural} + h_{phylo}'
\end{equation}

This additive fusion allows phylogenetic information to augment structural
features without increasing model complexity.

\textbf{Stage 2: Cross-Attention Fusion}. The combined structural-phylo
representation is fused with semantic features using bidirectional cross-attention:
\begin{equation}
    h_{fused} = \text{CrossAttention}(Q=h_{semantic}, K=h_{combined}, V=h_{combined})
\end{equation}

The final 512-dimensional fused representation ($h_{semantic} \| h_{combined}$)
is passed to a classifier with hidden layers [128, 64] and dropout 0.2.

\subsection{Ranking-Aware Training}

We use a combined loss function with three components:

\begin{equation}
    \mathcal{L} = \lambda_1 \cdot \mathcal{L}_{focal} + \lambda_2 \cdot \mathcal{L}_{rank} + \lambda_3 \cdot \mathcal{L}_{phylo}
\end{equation}

where $\lambda_1 = 0.7$, $\lambda_2 = 0.3$, and $\lambda_3 = 0.05$. The reduced
phylogenetic regularization weight (0.05 vs 0.1) was found to improve performance
by allowing the model more flexibility while still encouraging evolutionary consistency.

\textbf{Focal Loss}~\cite{lin2017focal} handles the 37:1 class imbalance:
\begin{equation}
    \mathcal{L}_{focal} = -\alpha_t (1 - p_t)^\gamma \log(p_t)
\end{equation}
with $\alpha = [0.15, 0.85]$ and $\gamma = 2.5$.

\textbf{Ranking Loss} (RankNet-style) aligns with APFD:
\begin{equation}
    \mathcal{L}_{rank} = \log(1 + e^{-(s_{fail} - s_{pass} - m)})
\end{equation}
where $s_{fail}$ and $s_{pass}$ are scores for fail/pass test cases within
the same build, and $m = 0.5$ is the margin.

\textbf{Phylogenetic Regularization} penalizes predictions inconsistent with
evolutionary structure:
\begin{equation}
    \mathcal{L}_{phylo} = \sum_{(c_i, c_j) \in E_{DAG}} w_{phylo}(c_i, c_j) \cdot |p(c_i) - p(c_j)|
\end{equation}

This encourages similar failure predictions for phylogenetically close commits,
encoding the inductive bias that evolutionary proximity implies behavioral similarity.

We apply hard negative mining, selecting the top-5 hardest pass examples
per build for ranking loss computation.

%------------------------------------------------------------------------------
% SECTION 5: EXPERIMENTAL DESIGN
%------------------------------------------------------------------------------
\section{Experimental Design}
\label{sec:experimental}

\subsection{Research Questions}

\begin{itemize}
    \item \textbf{RQ1 (Effectiveness)}: How effective is \filopriori{} compared to baseline methods?
    \item \textbf{RQ2 (Components)}: What is the contribution of each architectural component?
    \item \textbf{RQ3 (Robustness)}: How robust is \filopriori{} across different time periods?
    \item \textbf{RQ4 (Sensitivity)}: How sensitive is \filopriori{} to hyperparameter choices?
\end{itemize}

\subsection{Dataset}

We use the QTA (Qodo Test Automation) dataset from a commercial software project:

\begin{table}[h]
\centering
\caption{Dataset Statistics}
\label{tab:dataset}
\begin{tabular}{lr}
\toprule
\textbf{Statistic} & \textbf{Value} \\
\midrule
Total test executions & 52,102 \\
Unique builds & 1,339 \\
Builds with failures & 277 (20.7\%) \\
Unique test cases & 2,347 \\
Pass:Fail ratio & 37:1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Baselines}

We compare against eight baselines:

\textbf{Heuristic Baselines}:
\begin{itemize}
    \item \textbf{Random}: Random ordering (expected APFD $\approx$ 0.5)
    \item \textbf{Recency}: Prioritize recently failed tests
    \item \textbf{RecentFailureRate}: Failure rate in last 5 builds
    \item \textbf{FailureRate}: Historical failure rate
    \item \textbf{GreedyHistorical}: Combined heuristics
\end{itemize}

\textbf{ML Baselines}:
\begin{itemize}
    \item \textbf{Logistic Regression}
    \item \textbf{Random Forest}
    \item \textbf{XGBoost}
\end{itemize}

\subsection{Evaluation Metrics}

\begin{itemize}
    \item \textbf{APFD}: Primary metric, computed per build
    \item \textbf{Statistical tests}: Wilcoxon signed-rank test ($\alpha = 0.05$)
    \item \textbf{Confidence intervals}: 95\% bootstrap CI (1000 iterations)
\end{itemize}

\subsection{Implementation Details}

\begin{itemize}
    \item \textbf{Framework}: PyTorch 2.0, PyTorch Geometric 2.3
    \item \textbf{Hardware}: NVIDIA RTX 3090 (24GB VRAM)
    \item \textbf{Training}: 50 epochs, batch size 32, AdamW optimizer
    \item \textbf{Learning rate}: $3 \times 10^{-5}$ with cosine annealing
    \item \textbf{Early stopping}: Patience 15, monitoring val\_f1\_macro
\end{itemize}

%------------------------------------------------------------------------------
% SECTION 6: RESULTS
%------------------------------------------------------------------------------
\section{Results}
\label{sec:results}

\input{sections/results_ieee}

%------------------------------------------------------------------------------
% SECTION 7: DISCUSSION
%------------------------------------------------------------------------------
\section{Discussion}
\label{sec:discussion}

\input{sections/discussion_ieee}

%------------------------------------------------------------------------------
% SECTION 8: THREATS TO VALIDITY
%------------------------------------------------------------------------------
\section{Threats to Validity}
\label{sec:threats}

\input{sections/threats_ieee}

%------------------------------------------------------------------------------
% SECTION 9: CONCLUSION
%------------------------------------------------------------------------------
\section{Conclusion}
\label{sec:conclusion}

We presented \filopriori{}, a bio-inspired approach for Test Case Prioritization
that introduces the phylogenetic metaphor to software testing. By treating the
Git DAG as an evolutionary tree and computing phylogenetic distances between
commits, we provide a principled framework for modeling software evolution
that existing linear approaches ignore.

Our key contributions include:
\begin{itemize}
    \item The first application of computational phylogenetics concepts to TCP,
    including phylogenetic distance kernels and evolutionary regularization.
    \item A novel architecture combining Phylo-Encoder (GGNN), Code-Encoder (GATv2),
    and Hierarchical Attention at micro/meso/macro scales.
    \item Empirical validation showing 14.6\% improvement over random ordering
    ($p < 0.001$) with Graph Attention contributing +17.0\% to performance.
    \item Robust temporal generalization (APFD: 0.619--0.663 across time periods).
\end{itemize}

The phylogenetic metaphor is not merely linguistic---it provides mathematical
foundations (distance kernels, signal propagation) that align with how software
actually evolves through branching and merging.

\textbf{Future Work.} We plan to: (1) evaluate on additional datasets with rich
Git histories, (2) extend the phylogenetic model to incorporate mutation rates
(code churn) as branch lengths, (3) investigate cross-project transfer learning
using phylogenetic embeddings, and (4) develop real-time prioritization integrated
with CI/CD pipelines.

\textbf{Data Availability.} Our replication package, including source code,
trained models, configuration files, and anonymized dataset, is available at:
\url{https://github.com/[anonymized]/filo-priori-v9}

%------------------------------------------------------------------------------
% ACKNOWLEDGMENTS
%------------------------------------------------------------------------------
\section*{Acknowledgments}
This work was supported by [funding information]. We thank [acknowledgments].

%------------------------------------------------------------------------------
% REFERENCES
%------------------------------------------------------------------------------
\bibliographystyle{IEEEtran}
\bibliography{references_ieee}

%------------------------------------------------------------------------------
% BIOGRAPHY (Optional for TSE)
%------------------------------------------------------------------------------
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{placeholder.png}}]{Acauan C. Ribeiro}
is a researcher at the Institute of Computing (IComp), Federal University of
Amazonas (UFAM), Brazil. His research interests include software testing,
machine learning for software engineering, and continuous integration.
\end{IEEEbiography}

\end{document}
