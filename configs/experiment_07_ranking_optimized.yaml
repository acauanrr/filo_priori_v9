# =============================================================================
# Experimento 07: RANKING-OPTIMIZED FILO-PRIORI
# =============================================================================
# OBJETIVO: Superar FailureRate baseline (APFD = 0.6289)
# TARGET:   APFD >= 0.65 (+5% improvement over current 0.6171)
#
# MUDANÇAS CRÍTICAS:
# 1. RANKING LOSS HABILITADO - RankNet-style pairwise loss
# 2. WEIGHTED FOCAL LOSS - Mais forte para imbalance 19:1
# 3. GROUPED BATCH SAMPLING - Permite comparação intra-build
# 4. HARD NEGATIVE MINING - Foca nos casos mais difíceis
# 5. THRESHOLD OPTIMIZATION - Calibração para APFD
#
# JUSTIFICATIVA CIENTÍFICA:
# - RankNet (Burges et al., 2005): Loss específica para ranking
# - Focal Loss (Lin et al., 2017): Superior para class imbalance
# - Hard Negative Mining (He et al., 2016): Foca em hard examples
#
# IMPACTO ESPERADO:
# - APFD: 0.6171 → 0.65-0.68 (+5-10% improvement)
# - Deve SUPERAR FailureRate (0.6289) e todos os baselines
# =============================================================================

experiment:
  name: "experiment_07_ranking_optimized"
  version: "7.0"
  description: "Ranking-optimized model to beat FailureRate baseline"
  seed: 42

# Data Configuration (identical to exp 06)
data:
  train_path: "datasets/train.csv"
  test_path: "datasets/test.csv"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  binary_classification: true
  binary_strategy: "pass_vs_fail"
  binary_positive_class: "Pass"
  binary_negative_class: "Fail"
  smote:
    enabled: false

# Text and Embedding (identical to exp 06)
text:
  num_commits_to_keep: 5
  max_commit_length: 2000
  max_summary_length: 500
  max_steps_length: 1000

commit:
  max_commits_per_tc: 10
  include_commit_metadata: true

embedding:
  model_name: "sentence-transformers/all-mpnet-base-v2"
  embedding_dim: 768
  combined_embedding_dim: 1536
  max_length: 384
  batch_size: 128
  normalize_embeddings: true
  device: "cuda"
  use_cache: true
  cache_dir: "cache"

semantic:
  model_name: "sentence-transformers/all-mpnet-base-v2"
  embedding_dim: 768
  combined_embedding_dim: 1536
  max_length: 384
  batch_size: 128

# Structural Features - 10 selected features (same as exp 06)
structural:
  input_dim: 10
  extractor:
    use_v2_5: true
    recent_window: 5
    very_recent_window: 2
    medium_term_window: 10
    min_history: 2
    cache_path: "cache/structural_features_v2_5.pkl"

# Graph Configuration (identical to exp 06)
graph:
  build_graph: true
  use_multi_edge: true
  edge_types: [co_failure, co_success, semantic]
  edge_weights:
    co_failure: 1.0
    co_success: 0.5
    semantic: 0.3
  min_co_occurrences: 1
  weight_threshold: 0.05
  semantic_top_k: 5
  semantic_threshold: 0.75
  cache_path: "cache/multi_edge_graph.pkl"
  type: "co_failure"

# Model Architecture (same as exp 06)
model:
  type: "dual_stream"
  num_classes: 2

  semantic:
    input_dim: 1536
    hidden_dim: 256
    num_layers: 2
    dropout: 0.1
    activation: "gelu"

  structural:
    input_dim: 10
    hidden_dim: 64
    num_layers: 2
    dropout: 0.1
    activation: "gelu"

  gnn:
    type: "GAT"
    hidden_dim: 128
    num_layers: 1
    num_heads: 2
    dropout: 0.1
    activation: "elu"

  fusion:
    input_dim: 320
    hidden_dim: 256
    num_layers: 2
    dropout: 0.15
    activation: "gelu"

  classifier:
    input_dim: 256
    hidden_dim: 128
    num_classes: 2
    dropout: 0.2

# =============================================================================
# TRAINING - MUDANÇAS CRÍTICAS AQUI
# =============================================================================
training:
  num_epochs: 50
  epochs: 50
  batch_size: 32
  learning_rate: 0.00003  # 3e-5 (proven optimal)
  weight_decay: 0.0001

  optimizer: "adamw"
  scheduler:
    type: "cosine"
    eta_min: 0.000001
  warmup_epochs: 5

  gradient_clip: 1.0
  accumulation_steps: 1

  early_stopping:
    patience: 15
    min_delta: 0.001
    monitor: "val_f1_macro"
    mode: "max"

  # =========================================================================
  # MUDANÇA 1: SAMPLING (sem balanceamento)
  # =========================================================================
  sampling:
    use_balanced_sampling: false

  # =========================================================================
  # MUDANÇA 2: WEIGHTED FOCAL LOSS (mais forte para imbalance 19:1)
  # =========================================================================
  loss:
    type: "weighted_focal"        # MUDOU de "weighted_ce"
    use_class_weights: true       # Automatic class weights
    focal_alpha: 0.75             # Alto peso para classe minoritária (Fail)
    focal_gamma: 2.5              # Foco em hard examples
    label_smoothing: 0.0

  # =========================================================================
  # MUDANÇA 3: RANKING LOSS HABILITADO (crítico!)
  # =========================================================================
  ranking:
    enabled: true                 # CRÍTICO: Era false!
    use_grouped_sampler: true     # CRÍTICO: Agrupa por Build_ID
    weight: 0.3                   # Peso do ranking loss (30% do total)
    loss_type: "logistic"         # RankNet-style (softplus)
    score_type: "logit"           # Usa logits (mais estável que probs)
    margin: 0.5                   # Margem para separação
    # Hard Negative Mining
    hard_negative_top_k: 5        # Top 5 Pass mais difíceis
    hard_negative_percent: 0.2    # 20% dos Pass como hard negatives
    max_pairs_per_build: 50       # Limite de pares por build
    start_epoch: 3                # Começa ranking loss após warmup

# Legacy loss config
loss:
  type: "weighted_focal"
  focal_alpha: 0.75
  focal_gamma: 2.5
  label_smoothing: 0.0

# =========================================================================
# MUDANÇA 4: THRESHOLD OPTIMIZATION HABILITADO
# =========================================================================
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_macro"
    - "f1_weighted"
    - "auprc_macro"
    - "auroc"

  threshold_search:
    enabled: true                 # MUDOU de false!
    range: [0.1, 0.9]             # Ampliado
    step: 0.02                    # Mais granular
    optimize_for: "f1_macro"      # Otimiza F1

# Ranking (identical)
ranking:
  method: "probability"
  reverse: true
  apfd_calculation:
    enabled: true
    fault_column: "verdict"
    fault_value: "Fail"

# System
system:
  device: "cuda"
  num_workers: 4
  pin_memory: true
  use_amp: false
  deterministic: true
  benchmark: false

hardware:
  device: "cuda"
  num_workers: 4

logging:
  level: "INFO"
  log_dir: "logs"
  tensorboard: false

checkpoint:
  save_best: true
  save_last: true
  monitor: "val_f1_macro"
  mode: "max"

output:
  results_dir: "results/experiment_07_ranking_optimized"
  save_predictions: true
  save_rankings: true
  save_apfd: true
  save_plots: true
