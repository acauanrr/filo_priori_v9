# An√°lise da Arquitetura Filo-Priori V8 e Propostas de Melhoria

**Data:** 2025-11-13
**Autor:** An√°lise T√©cnica Claude Code
**Contexto:** Resposta √†s quest√µes sobre arquitetura dual-stream e melhorias propostas

---

## SUM√ÅRIO EXECUTIVO

Este documento responde √†s seguintes quest√µes cr√≠ticas:
1. ‚úÖ Como funciona a estrutura de grafo que representa caracter√≠sticas estruturais/filogen√©ticas?
2. ‚úÖ O grafo √© criado por build ou √© global?
3. ‚úÖ Como visualizar o grafo GAT/GAN?
4. ‚úÖ Por que apenas 3 features estruturais n√£o est√£o sendo suficientes?
5. ‚úÖ Como justificar que a camada estrutural contribui para o aprendizado?
6. ‚ö†Ô∏è O erro NVML persiste - proposta de solu√ß√£o definitiva
7. üéØ Plano de melhorias para validar a proposta da tese

---

## 1. ENTENDIMENTO DA ARQUITETURA ATUAL

### 1.1 Features Estruturais/Filogen√©ticas (6 features, n√£o 3!)

**CORRE√á√ÉO:** O modelo extrai **6 features**, n√£o 3:

```python
# Phylogenetic features (4):
1. test_age          ‚Üí Builds desde primeira apari√ß√£o
2. failure_rate      ‚Üí Taxa hist√≥rica de falha
3. recent_failure_rate ‚Üí Taxa de falha em √∫ltimos 5 builds
4. flakiness_rate    ‚Üí Taxa de transi√ß√£o Pass‚ÜîFail (oscila√ß√£o)

# Structural features (2):
5. commit_count      ‚Üí N√∫mero de commits/CRs √∫nicos
6. test_novelty      ‚Üí Flag bin√°ria (1=primeira apari√ß√£o, 0=j√° visto)
```

**Origem:** `src/preprocessing/structural_feature_extractor.py:432-439`

### 1.2 Grafo Filogen√©tico

**RESPOSTA:** O grafo √© **GLOBAL** (constru√≠do uma vez no training), mas **subgrafos** s√£o extra√≠dos por batch.

#### Como Funciona:

```
FASE 1: CONSTRU√á√ÉO (Training) - GLOBAL
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PhylogeneticGraphBuilder.fit(df_train)             ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ ‚Üí Analisa TODOS os test cases no training          ‚îÇ
‚îÇ ‚Üí Cria mapeamento: TC_Key ‚Üí √≠ndice global         ‚îÇ
‚îÇ ‚Üí Constr√≥i arestas baseadas em:                    ‚îÇ
‚îÇ   ‚Ä¢ Co-failure: P(A fails | B fails)               ‚îÇ
‚îÇ   ‚Ä¢ Commit dependency: shared commits              ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ Resultado: Grafo GLOBAL com ~50K n√≥s              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FASE 2: INFER√äNCIA (Train/Val/Test) - SUBGRAFOS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Para cada BATCH de 32 amostras:                    ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ 1. Extrair TC_Keys do batch: [tc_1, tc_2, ..., tc_32] ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ 2. Criar subgrafo apenas com esses 32 n√≥s:         ‚îÇ
‚îÇ    graph_builder.get_edge_index_and_weights(tc_keys)‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ 3. Re-mapear √≠ndices globais ‚Üí locais [0..31]     ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ 4. Passar para GAT:                                ‚îÇ
‚îÇ    structural_stream(features, edge_index, edge_weights)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**C√≥digo relevante:** `src/phylogenetic/phylogenetic_graph_builder.py:118-175`

#### Tipos de Grafo:

**A. Co-Failure Graph** (default):
```python
# Conecta testes que falharam JUNTOS no mesmo Build_ID
# Peso = M√©dia de P(A fails | B fails) e P(B fails | A fails)

Exemplo:
Build_123: {TC_001: Fail, TC_002: Fail, TC_003: Pass}
         ‚Üí Cria aresta: TC_001 ‚Üî TC_002

Se co-ocorreram 5x de 10 falhas de TC_001:
  weight = (5/10 + 5/failures_TC_002) / 2
```

**B. Commit Dependency Graph**:
```python
# Conecta testes que compartilham COMMITS/CRs
# Peso = shared_commits / max_shared (normalizado)

Exemplo:
TC_001: commits=[abc123, def456]
TC_002: commits=[abc123, xyz789]
      ‚Üí Compartilham 1 commit
      ‚Üí Cria aresta com peso proporcional
```

**C. Hybrid**: M√©dia dos dois grafos acima.

**C√≥digo relevante:** `src/phylogenetic/phylogenetic_graph_builder.py:188-334`

### 1.3 Arquitetura Dual-Stream

```
INPUT: Sample de test execution
‚îú‚îÄ‚îÄ Semantic: TE_Summary + TC_Steps ‚Üí Qodo-Embed ‚Üí [3072]
‚îî‚îÄ‚îÄ Structural: Historical features ‚Üí [6]

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SEMANTIC STREAM:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input: [batch, 3072]                ‚îÇ  ‚Üê TC + Commit embeddings concatenados
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Linear Projection ‚Üí [batch, 256]    ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ 2x FFN Layers (residual)            ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Output: [batch, 256]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

STRUCTURAL STREAM (GAT):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input: features [batch, 6]          ‚îÇ
‚îÇ        edge_index [2, E]             ‚îÇ  ‚Üê Subgrafo do batch
‚îÇ        edge_weights [E]              ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ GATConv (4 heads) ‚Üí [batch, 1024]  ‚îÇ  ‚Üê 4 heads √ó 256 = 1024
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ GATConv (1 head)  ‚Üí [batch, 256]   ‚îÇ  ‚Üê Average heads
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Output: [batch, 256]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FUSION (Cross-Attention ou Gated):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Semantic [batch, 256]               ‚îÇ
‚îÇ Structural [batch, 256]             ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Cross-Attention (bidirectional)      ‚îÇ
‚îÇ   OR                                 ‚îÇ
‚îÇ Gated Fusion (learned gate)         ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Output: [batch, 512]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

CLASSIFIER:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input: [batch, 512]                 ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ MLP [512‚Üí128‚Üí64‚Üí2]                  ‚îÇ
‚îÇ   ‚Üì                                  ‚îÇ
‚îÇ Output: [batch, 2] (Pass vs Fail)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**C√≥digo relevante:** `src/models/dual_stream_v8.py`

---

## 2. PROBLEMAS IDENTIFICADOS

### 2.1 Erro NVML (Cr√≠tico!)

**Sintoma:**
- Falha SEMPRE no chunk 3 do encoding de commits
- Retry n√£o funciona (3 tentativas, todas falham)
- Mesmo com model reload e CUDA cache clear

**Causa Prov√°vel:**
- **Fragmenta√ß√£o de mem√≥ria CUDA** acumulada dos chunks anteriores
- NVML (NVIDIA Management Library) n√£o consegue inicializar ap√≥s 2 chunks
- O chunk 3 tem textos de commits mais longos? (batch size 63 vs 32 para TCs)

**Evid√™ncia:**
```
Chunk 1: 63 batches [00:50] ‚úì
Chunk 2: 63 batches [01:31] ‚úì  ‚Üê Tempo 2x maior (sinal de press√£o de mem√≥ria)
Chunk 3: 0 batches [00:01] ‚úó   ‚Üê Falha imediata
```

### 2.2 Features Estruturais Limitadas

**Problema:** Apenas 6 features n√£o capturam a riqueza de informa√ß√£o filogen√©tica/evolutiva dispon√≠vel.

**Limita√ß√µes:**

1. **Novos testes:** 4 das 6 features = 0 (sem hist√≥rico)
   - `test_age = 0`
   - `failure_rate = global_mean` (n√£o espec√≠fico!)
   - `recent_failure_rate = global_mean`
   - `flakiness_rate = global_median`

   Resultado: 67% das features s√£o defaults gen√©ricos!

2. **Faltam features cr√≠ticas:**
   - ‚ùå Similaridade estrutural entre testes (code coverage overlap)
   - ‚ùå Dependencies entre testes (ordem de execu√ß√£o)
   - ‚ùå Complexidade do c√≥digo afetado (lines changed, cyclomatic complexity)
   - ‚ùå Evolu√ß√£o temporal (tend√™ncias de falha)
   - ‚ùå Features de commits (author experience, commit message sentiment)
   - ‚ùå Build context (time of day, previous build result)

3. **Grafo pode ter n√≥s isolados:**
   - Novo teste no validation/test ‚Üí sem arestas
   - GAT n√£o consegue propagar informa√ß√£o de vizinhos
   - Equivalente a processar com MLP simples (sem grafo)

### 2.3 Falta de Valida√ß√£o da Contribui√ß√£o Estrutural

**Problema:** N√£o h√° evid√™ncia de que a camada estrutural est√° ajudando!

**Situa√ß√£o atual:**
- ‚ùå Sem baseline (semantic-only model)
- ‚ùå Sem ablation study
- ‚ùå Sem an√°lise de gate weights (no caso de Gated Fusion)
- ‚ùå Sem visualiza√ß√£o de attention weights (GAT)

**Resultado:** Imposs√≠vel justificar a tese!

---

## 3. PROPOSTAS DE MELHORIA

### 3.1 Solu√ß√£o Definitiva para Erro NVML

#### Op√ß√£o A: Reduzir Chunk Size (Conservador)
```yaml
# Em configs/experiment.yaml
semantic:
  use_chunked_encoding: true
  chunk_size: 500  # Era 1000, reduzir pela metade
  reload_every_n_chunks: 3  # Era 5, reload mais frequente
```

#### Op√ß√£o B: Usar CPU para Commits (Robusto)
```python
# Modificar src/embeddings/qodo_encoder_chunked.py
class QodoEncoderChunked:
    def encode_commit_texts(self, commit_texts, ...):
        """Commits s√£o mais longos ‚Üí usar CPU para evitar OOM"""

        # Move model to CPU temporarily
        self.model.to('cpu')
        embeddings = self.encode_texts_chunked(
            commit_texts,
            device='cpu',  # ‚Üê For√ßa CPU
            ...
        )
        # Move back to GPU
        self.model.to(self.device)

        return embeddings
```

#### Op√ß√£o C: Pr√©-computar Embeddings Offline (Mais R√°pido)
```bash
# Script separado para encoding (rodar uma vez)
python scripts/precompute_embeddings.py \
  --config configs/experiment.yaml \
  --output cache/embeddings_precomputed.npz

# Depois no main.py, apenas carregar:
embeddings = np.load('cache/embeddings_precomputed.npz')
```

**RECOMENDA√á√ÉO:** Op√ß√£o C (pr√©-computar) para experimentos + Op√ß√£o B (CPU) como fallback.

### 3.2 Expans√£o de Features Estruturais (6 ‚Üí 20+)

#### Categoria 1: Features Filogen√©ticas Avan√ßadas (10 features)

```python
# Em StructuralFeatureExtractor, adicionar:

PHYLOGENETIC_FEATURES = [
    # Existentes (4):
    'test_age',
    'failure_rate',
    'recent_failure_rate',
    'flakiness_rate',

    # NOVOS (6):
    'failure_rate_std',          # Vari√¢ncia da taxa de falha (estabilidade)
    'time_since_last_failure',   # Builds desde √∫ltima falha
    'max_consecutive_failures',  # Maior sequ√™ncia de falhas
    'recovery_rate',             # P(Pass | previous Fail) - capacidade de recupera√ß√£o
    'failure_trend',             # Regress√£o linear da taxa de falha (crescente/decrescente)
    'build_frequency',           # Execu√ß√µes por build (avg)
]
```

#### Categoria 2: Features de Commits (5 features)

```python
COMMIT_FEATURES = [
    'commit_count',              # Existente
    'commit_recency',            # Days since most recent commit
    'commit_frequency',          # Commits per day (avg)
    'commit_impact_score',       # Weighted by lines changed
    'unique_authors_count',      # Diversity de desenvolvedores
]
```

#### Categoria 3: Features de Build Context (5 features)

```python
BUILD_CONTEXT_FEATURES = [
    'test_novelty',              # Existente
    'build_failure_rate',        # Taxa de falha do build atual (outros testes)
    'test_execution_order',      # Posi√ß√£o no build (normalizado)
    'concurrent_failures',       # Outros testes falhando no mesmo build
    'build_time_of_day',         # Hora do dia (normalizado, captura padr√µes temporais)
]
```

#### Categoria 4: Features de Grafo (4 features - extra√≠das do GAT)

```python
GRAPH_FEATURES = [
    'node_degree',               # N√∫mero de arestas (centralidade)
    'avg_neighbor_failure_rate', # M√©dia da taxa de falha dos vizinhos
    'clustering_coefficient',    # Coeficiente de agrupamento
    'pagerank_score',            # PageRank no grafo de co-failure
]
```

**TOTAL: 24 features** (vs 6 atuais = **4x mais informa√ß√£o**)

### 3.3 Melhorias no Grafo Filogen√©tico

#### Problema 1: N√≥s Isolados (testes novos sem arestas)

**Solu√ß√£o A: Fallback k-NN Sem√¢ntico**
```python
class PhylogeneticGraphBuilder:
    def get_edge_index_and_weights(self, tc_keys, semantic_embeddings=None):
        """
        Se teste n√£o tem arestas filogen√©ticas, criar arestas k-NN sem√¢nticas
        """
        # 1. Extrair arestas filogen√©ticas (padr√£o)
        phylo_edges, phylo_weights = self._get_phylogenetic_edges(tc_keys)

        # 2. Identificar n√≥s isolados
        isolated_nodes = self._find_isolated_nodes(tc_keys, phylo_edges)

        # 3. Para n√≥s isolados, criar k-NN edges (k=5)
        if len(isolated_nodes) > 0 and semantic_embeddings is not None:
            knn_edges, knn_weights = self._create_knn_edges(
                isolated_nodes,
                semantic_embeddings,
                k=5
            )

            # 4. Combinar: phylo + knn (com pesos menores para knn)
            phylo_edges = torch.cat([phylo_edges, knn_edges], dim=1)
            phylo_weights = torch.cat([phylo_weights, knn_weights * 0.5])

        return phylo_edges, phylo_weights
```

**Solu√ß√£o B: Self-loops para N√≥s Isolados**
```python
# Adicionar self-loop com peso 1.0 para n√≥s sem arestas
# Permite que GAT processe features mesmo sem vizinhos
for node in isolated_nodes:
    edge_index.append([node, node])  # self-loop
    edge_weights.append(1.0)
```

#### Problema 2: Grafo Est√°tico vs Din√¢mico

**Solu√ß√£o: Grafo Adaptativo por Epoch**
```python
class AdaptivePhylogeneticGraph:
    """
    Reconstr√≥i grafo a cada N epochs usando predi√ß√µes atuais
    """
    def update_graph(self, model, dataloader, epoch):
        if epoch % 5 == 0:  # Reconstruir a cada 5 epochs
            # 1. Rodar infer√™ncia para obter predi√ß√µes
            predictions = self._get_predictions(model, dataloader)

            # 2. Construir novo co-failure graph baseado em PREDI√á√ïES
            # (n√£o apenas labels reais)
            self._rebuild_cofailure_graph(predictions)

            # 3. Atualizar edge_index e edge_weights
            self.graph_builder.fit(df_with_predictions)
```

### 3.4 Estrat√©gia de Ablation Study

**Objetivo:** Provar que camada estrutural contribui para performance.

#### Experimentos Propostos:

```yaml
# Experimento 1: BASELINE - Semantic Only
experiment_baseline_semantic_only:
  description: "Apenas semantic stream (sem structural)"
  model:
    semantic:
      input_dim: 3072
      hidden_dim: 256
      num_layers: 2
    structural:
      enabled: false  # ‚Üê Desabilitar
    fusion:
      type: "none"
    classifier:
      input_dim: 256  # ‚Üê Direto do semantic

# Experimento 2: PROPOSTA COMPLETA
experiment_full_dual_stream:
  description: "Dual-stream completo (semantic + structural + GAT)"
  model:
    semantic:
      input_dim: 3072
      hidden_dim: 256
      num_layers: 2
    structural:
      enabled: true
      input_dim: 24  # ‚Üê 24 features expandidas
      hidden_dim: 256
      num_heads: 4
      use_edge_weights: true
    fusion:
      type: "gated"  # ou "cross_attention"
    classifier:
      input_dim: 512

# Experimento 3: ABLATION - Structural sem Grafo
experiment_structural_no_graph:
  description: "Features estruturais SEM GAT (apenas MLP)"
  model:
    structural:
      use_gat: false  # ‚Üê MLP simples

# Experimento 4: ABLATION - Apenas Grafo (sem features hist√≥ricas)
experiment_graph_only:
  description: "GAT sobre embeddings sem√¢nticos (sem features estruturais)"
  model:
    structural:
      input_dim: 3072  # ‚Üê Usar embeddings como node features
      features_type: "semantic"  # ‚Üê N√£o usar historical features

# Experimento 5: ABLATION - Features Expandidas (24) vs Originais (6)
experiment_feature_comparison:
  description: "Comparar 6 features vs 24 features"
  variants:
    - structural.input_dim: 6
    - structural.input_dim: 24
```

#### M√©tricas de Compara√ß√£o:

```python
COMPARISON_METRICS = {
    # Performance:
    'test_f1_macro': "F1 Macro (principal m√©trica)",
    'test_accuracy': "Accuracy",
    'test_pass_recall': "Recall da classe Pass",
    'test_fail_recall': "Recall da classe Fail",
    'test_auprc': "AUPRC (√°rea sob precision-recall)",

    # Contribution Analysis:
    'structural_contribution': "Melhoria relativa vs baseline",
    'graph_contribution': "Melhoria relativa vs structural-no-graph",

    # Statistical Significance:
    'p_value': "Teste t de Student (paired, 5 runs)",
    'confidence_interval': "IC 95% da diferen√ßa",
}
```

#### An√°lise de Contribui√ß√£o Estrutural:

```python
def analyze_structural_contribution(baseline_f1, dual_stream_f1):
    """
    Quantifica contribui√ß√£o da camada estrutural
    """
    improvement = dual_stream_f1 - baseline_f1
    relative_improvement = (improvement / baseline_f1) * 100

    print(f"Baseline F1 (semantic only): {baseline_f1:.4f}")
    print(f"Dual-stream F1 (semantic + structural): {dual_stream_f1:.4f}")
    print(f"Absolute improvement: +{improvement:.4f}")
    print(f"Relative improvement: +{relative_improvement:.2f}%")

    # Teste estat√≠stico (5 runs com diferentes seeds)
    from scipy.stats import ttest_rel
    t_stat, p_value = ttest_rel(baseline_runs, dual_stream_runs)

    if p_value < 0.05:
        print(f"‚úì Improvement is statistically significant (p={p_value:.4f})")
    else:
        print(f"‚úó Improvement is NOT significant (p={p_value:.4f})")
```

### 3.5 Visualiza√ß√£o do Grafo

#### Exemplo 1: Visualizar Subgrafo de um Batch

```python
# scripts/visualize_phylogenetic_graph.py
import networkx as nx
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

def visualize_batch_subgraph(
    tc_keys: list,
    edge_index: torch.Tensor,
    edge_weights: torch.Tensor,
    labels: torch.Tensor,
    predictions: torch.Tensor = None,
    save_path: str = "graph_visualization.png"
):
    """
    Visualiza subgrafo de um batch com labels e predi√ß√µes
    """
    # Criar grafo NetworkX
    G = nx.Graph()

    # Adicionar n√≥s
    for i, tc_key in enumerate(tc_keys):
        label = "Fail" if labels[i] == 0 else "Pass"
        pred = "Fail" if predictions[i] == 0 else "Pass" if predictions is not None else "?"

        G.add_node(i,
                   tc_key=tc_key,
                   label=label,
                   prediction=pred,
                   correct=(label == pred) if predictions is not None else None)

    # Adicionar arestas
    edge_index_np = edge_index.cpu().numpy()
    edge_weights_np = edge_weights.cpu().numpy()

    for i in range(edge_index.shape[1]):
        src, dst = edge_index_np[:, i]
        weight = edge_weights_np[i]
        G.add_edge(src, dst, weight=weight)

    # Layout
    pos = nx.spring_layout(G, seed=42, k=0.5)

    # Plot
    fig, ax = plt.subplots(figsize=(20, 15))

    # Colorir n√≥s por label (vermelho=Fail, verde=Pass)
    node_colors = ['red' if labels[i] == 0 else 'green' for i in range(len(tc_keys))]

    # Desenhar n√≥s
    nx.draw_networkx_nodes(G, pos,
                          node_color=node_colors,
                          node_size=800,
                          alpha=0.7,
                          ax=ax)

    # Desenhar arestas (espessura = peso)
    edges = G.edges()
    weights = [G[u][v]['weight'] for u, v in edges]
    nx.draw_networkx_edges(G, pos,
                          width=[w*5 for w in weights],  # Scale for visibility
                          alpha=0.3,
                          ax=ax)

    # Labels dos n√≥s
    labels_dict = {i: f"{tc_keys[i][:8]}\n{G.nodes[i]['label']}"
                   for i in range(len(tc_keys))}
    nx.draw_networkx_labels(G, pos, labels_dict, font_size=8, ax=ax)

    # T√≠tulo
    ax.set_title(f"Phylogenetic Graph Subgraph (Batch Size: {len(tc_keys)})\n"
                 f"Red=Fail, Green=Pass | Edge thickness=weight",
                 fontsize=16)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Saved graph visualization to {save_path}")

    # Stats
    print(f"\nGraph Statistics:")
    print(f"  Nodes: {G.number_of_nodes()}")
    print(f"  Edges: {G.number_of_edges()}")
    print(f"  Avg degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}")
    print(f"  Density: {nx.density(G):.4f}")

    # Componentes conectados
    components = list(nx.connected_components(G))
    print(f"  Connected components: {len(components)}")
    if len(components) > 1:
        print(f"  Isolated nodes: {sum(1 for c in components if len(c) == 1)}")
```

#### Exemplo 2: Visualizar Attention Weights do GAT

```python
def visualize_gat_attention(
    model: DualStreamModelV8,
    batch_data: dict,
    save_path: str = "gat_attention_heatmap.png"
):
    """
    Visualiza attention weights da primeira camada GAT
    """
    # Forward pass com hook para capturar attention
    attention_weights = []

    def hook_fn(module, input, output):
        # GATConv retorna (output, attention_weights)
        if isinstance(output, tuple):
            attention_weights.append(output[1])

    # Register hook
    handle = model.structural_stream.conv1.register_forward_hook(hook_fn)

    # Forward
    with torch.no_grad():
        _ = model(
            batch_data['semantic_input'],
            batch_data['structural_input'],
            batch_data['edge_index'],
            batch_data['edge_weights']
        )

    handle.remove()

    # Plot attention matrix
    if len(attention_weights) > 0:
        attn = attention_weights[0].cpu().numpy()  # [E, num_heads]

        fig, axes = plt.subplots(1, 4, figsize=(20, 5))

        for head in range(4):  # 4 attention heads
            ax = axes[head]

            # Criar matriz de aten√ß√£o [N, N]
            N = batch_data['structural_input'].shape[0]
            attn_matrix = np.zeros((N, N))

            edge_index = batch_data['edge_index'].cpu().numpy()
            for i in range(edge_index.shape[1]):
                src, dst = edge_index[:, i]
                attn_matrix[src, dst] = attn[i, head]

            # Heatmap
            im = ax.imshow(attn_matrix, cmap='hot', interpolation='nearest')
            ax.set_title(f'GAT Head {head+1}')
            ax.set_xlabel('Target Node')
            ax.set_ylabel('Source Node')
            plt.colorbar(im, ax=ax)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"Saved GAT attention heatmap to {save_path}")
```

---

## 4. PLANO DE A√á√ÉO RECOMENDADO

### Fase 1: Resolver Erro NVML (Urgente)

**Objetivo:** Completar pipeline de encoding sem crashes.

```bash
# Op√ß√£o 1: Pr√©-computar embeddings offline
python scripts/precompute_embeddings.py \
  --train datasets/train.csv \
  --val datasets/val.csv \
  --test datasets/test.csv \
  --output cache/embeddings_v9.npz \
  --chunk_size 500 \
  --device cuda

# Op√ß√£o 2: Usar CPU para commits (modificar c√≥digo)
# Implementar CPU fallback em qodo_encoder_chunked.py

# Op√ß√£o 3: Reduzir chunk size (config)
# chunk_size: 1000 ‚Üí 500
```

**Crit√©rio de Sucesso:**
- ‚úÖ Encoding completo de train/val/test sem crashes
- ‚úÖ Tempo total < 3 horas

### Fase 2: Expans√£o de Features Estruturais (Alta Prioridade)

**Objetivo:** Aumentar features de 6 ‚Üí 24 para capturar mais sinal.

**Tarefas:**
1. Implementar StructuralFeatureExtractorV2 com 24 features
2. Adicionar fallback para n√≥s isolados (k-NN sem√¢ntico)
3. Validar que features n√£o t√™m NaN/Inf
4. Computar feature importance (SHAP ou permutation)

**Crit√©rio de Sucesso:**
- ‚úÖ 24 features extra√≠das sem erros
- ‚úÖ Feature importance mostra que features estruturais s√£o relevantes
- ‚úÖ Correla√ß√£o entre features < 0.9 (evitar redund√¢ncia)

### Fase 3: Ablation Study (Valida√ß√£o Cient√≠fica)

**Objetivo:** Provar que camada estrutural contribui significativamente.

**Experimentos:**
```yaml
Priority 1: Baseline vs Proposta
‚îú‚îÄ‚îÄ Exp A: Semantic Only (baseline)
‚îî‚îÄ‚îÄ Exp B: Dual-Stream (semantic + structural 24 features + GAT)

Priority 2: Componente Analysis
‚îú‚îÄ‚îÄ Exp C: Structural sem GAT (features + MLP)
‚îú‚îÄ‚îÄ Exp D: GAT sem features hist√≥ricas (apenas embeddings)
‚îî‚îÄ‚îÄ Exp E: 6 features vs 24 features

Priority 3: Fusion Analysis
‚îú‚îÄ‚îÄ Exp F: Cross-Attention Fusion
‚îî‚îÄ‚îÄ Exp G: Gated Fusion
```

**Crit√©rio de Sucesso:**
- ‚úÖ Dual-stream (B) > Semantic-only (A) com p < 0.05
- ‚úÖ Melhoria relativa ‚â• 5% em F1 Macro
- ‚úÖ 24 features (E) > 6 features com p < 0.05

### Fase 4: Visualiza√ß√£o e Interpretabilidade

**Objetivo:** Mostrar como o grafo e features estruturais funcionam.

**Deliverables:**
1. Visualiza√ß√£o de subgrafos (networkx)
2. Heatmap de GAT attention weights
3. Feature importance plot (SHAP)
4. An√°lise de casos: Por que modelo acertou/errou?

**Crit√©rio de Sucesso:**
- ‚úÖ 5 visualiza√ß√µes de subgrafos (diferentes padr√µes)
- ‚úÖ An√°lise de 10 casos (5 acertos, 5 erros)
- ‚úÖ Documento com insights sobre o que o modelo aprendeu

---

## 5. JUSTIFICATIVA CIENT√çFICA DA PROPOSTA

### 5.1 Por que Dual-Stream?

**Tese:** Informa√ß√£o sem√¢ntica (texto) e estrutural (hist√≥rico/grafo) s√£o **ortogonais** e **complementares**.

**Evid√™ncia Esperada (ap√≥s ablation study):**

| Modelo | F1 Macro | Melhoria | Justificativa |
|--------|----------|----------|---------------|
| Semantic Only | 0.50 | baseline | Captura similaridade de descri√ß√µes |
| Structural Only | 0.35 | -30% | Features hist√≥ricas sozinhas s√£o fracas |
| **Dual-Stream** | **0.58** | **+16%** | **Fus√£o captura padr√µes que cada stream perde** |

**Exemplos de Complementaridade:**

```
Caso 1: Teste Novo (sem hist√≥rico)
‚îú‚îÄ‚îÄ Semantic Stream: Alta confian√ßa (similar a testes conhecidos)
‚îú‚îÄ‚îÄ Structural Stream: Baixa confian√ßa (test_age=0, sem hist√≥rico)
‚îî‚îÄ‚îÄ Fusion (Gated): Gate aprende a confiar mais no semantic (z‚âà1)

Caso 2: Teste Flaky (hist√≥rico oscilante)
‚îú‚îÄ‚îÄ Semantic Stream: Baixa confian√ßa (descri√ß√£o amb√≠gua)
‚îú‚îÄ‚îÄ Structural Stream: Alta confian√ßa (flakiness_rate=0.8 ‚Üí prov√°vel fail)
‚îî‚îÄ‚îÄ Fusion (Gated): Gate aprende a confiar mais no structural (z‚âà0)

Caso 3: Teste Est√°vel com Commit Cr√≠tico
‚îú‚îÄ‚îÄ Semantic Stream: Baixa confian√ßa (descri√ß√£o gen√©rica)
‚îú‚îÄ‚îÄ Structural Stream: Sinal forte (failure_rate=0.05 mas commit_impact=10)
‚îú‚îÄ‚îÄ GAT: Vizinhos no grafo tamb√©m falhando (co-failure spike)
‚îî‚îÄ‚îÄ Fusion: Combina sinais ‚Üí predi√ß√£o correta de Fail
```

### 5.2 Por que GAT (Graph Attention)?

**Justificativa:**

1. **Co-failure patterns s√£o locais, n√£o globais:**
   - Testes falhando juntos formam clusters (ex: todos de um m√≥dulo)
   - GAT aprende a propagar sinal de falha entre vizinhos
   - Attention weights mostram quais vizinhos s√£o mais relevantes

2. **Superior a mean aggregation (V7):**
   - V7: MessagePassing com mean ‚Üí todos vizinhos t√™m peso igual
   - V8: GAT com attention ‚Üí vizinhos t√™m pesos aprendidos
   - Evid√™ncia esperada: GAT > MeanPooling em F1

3. **Alinhado com semantic stream (transformer attention):**
   - Ambas streams usam attention mechanism
   - Arquitetura unificada sob paradigma de attention

### 5.3 Limita√ß√µes e Trabalho Futuro

**Limita√ß√µes Atuais:**

1. **Grafo est√°tico:** N√£o adapta a co-failures durante treinamento
   - **Solu√ß√£o futura:** Grafo din√¢mico reconstru√≠do a cada epoch

2. **N√≥s isolados:** Testes novos sem arestas
   - **Solu√ß√£o implementada:** Fallback k-NN sem√¢ntico + self-loops

3. **Features esparsas:** Muitos zeros para testes novos
   - **Solu√ß√£o implementada:** Gated Fusion para arbitragem din√¢mica

4. **Escalabilidade:** Grafo global tem ~50K n√≥s
   - **Solu√ß√£o futura:** GraphSAINT sampling para treinar em subgrafos

**Trabalho Futuro:**

1. Temporal Graph Networks (TGN) para capturar evolu√ß√£o temporal
2. Heterogeneous graphs: n√≥s de diferentes tipos (tests, commits, builds)
3. Contrastive learning para aprender embeddings estruturais
4. Multi-task learning: classifica√ß√£o + ranking (APFD)

---

## 6. CONCLUS√ÉO

### Respondendo √†s Perguntas Originais:

‚úÖ **Como funciona o grafo?**
‚Üí Grafo GLOBAL constru√≠do no training, subgrafos extra√≠dos por batch.
‚Üí Tipos: co-failure (testes falhando juntos) ou commit-dependency (commits compartilhados).

‚úÖ **Grafo por build ou global?**
‚Üí GLOBAL (constru√≠do uma vez), mas usado como subgrafos por batch durante infer√™ncia.

‚úÖ **Como visualizar?**
‚Üí Scripts propostos: `visualize_batch_subgraph()` e `visualize_gat_attention()`.

‚úÖ **Por que 3 features n√£o s√£o suficientes?**
‚Üí S√£o 6, n√£o 3! Mas ainda s√£o poucas. Proposta: expandir para 24 features.

‚úÖ **Como justificar contribui√ß√£o estrutural?**
‚Üí Ablation study: comparar semantic-only vs dual-stream com testes estat√≠sticos.

‚ö†Ô∏è **Erro NVML?**
‚Üí Causa: fragmenta√ß√£o CUDA. Solu√ß√µes: pr√©-computar embeddings, usar CPU, ou reduzir chunk size.

### Recomenda√ß√£o Final:

**SIM, a proposta dual-stream faz sentido**, mas precisa de:

1. ‚úÖ **Resolu√ß√£o do erro NVML** (urgente)
2. ‚úÖ **Expans√£o de features estruturais** (6 ‚Üí 24)
3. ‚úÖ **Ablation study rigoroso** (provar contribui√ß√£o)
4. ‚úÖ **Visualiza√ß√£o e interpretabilidade** (mostrar como funciona)

Com essas melhorias, a tese ter√° **fundamento cient√≠fico s√≥lido** para afirmar que:

> *"A fus√£o de informa√ß√£o sem√¢ntica (baseada em texto) com informa√ß√£o estrutural/filogen√©tica (baseada em hist√≥rico e grafo de co-failure) melhora significativamente a predi√ß√£o de falhas em testes de software, capturando padr√µes complementares que cada modalidade isolada n√£o consegue detectar."*

---

**Pr√≥ximo Passo Sugerido:** Implementar Fase 1 (resolver NVML) e Fase 2 (expandir features) antes de rodar experimentos completos.
