# Filo-Priori - RTPTorrent Dataset Configuration
# Dataset: Open-source regression test prioritization dataset (MSR 2020)
#
# Source: https://zenodo.org/records/3712290
# Paper: Mattis et al., "RTPTorrent: An Open-source Dataset for Evaluating
#        Regression Test Prioritization", MSR 2020
#
# Features:
# - 20 open-source Java projects
# - 100,000+ Travis CI build logs
# - Limited semantic information (test names only)
# - Good for evaluating structural features

experiment:
  name: "filo_priori_rtptorrent"
  version: "2.0.0"
  description: "RTPTorrent open-source dataset evaluation"
  seed: 42

# Data Configuration
data:
  train_path: "datasets/02_rtptorrent/processed/train.csv"
  test_path: "datasets/02_rtptorrent/processed/test.csv"

  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42

  binary_classification: true
  binary_strategy: "pass_vs_fail"
  binary_positive_class: "Pass"
  binary_negative_class: "Fail"

  smote:
    enabled: false

# Text Processing (adapted for RTPTorrent - less rich text)
text:
  num_commits_to_keep: 3
  max_commit_length: 500
  max_summary_length: 200
  max_steps_length: 0  # TC_Steps is empty for RTPTorrent

# Commit Extraction
commit:
  max_commits_per_tc: 5
  include_commit_metadata: false

# Semantic Embeddings with SBERT
# OPTIMIZED FOR RTX 4060 (6GB VRAM LIMIT)
embedding:
  model_name: "sentence-transformers/all-mpnet-base-v2"
  embedding_dim: 768
  combined_embedding_dim: 1536

  max_length: 128  # Shorter since text is simpler
  batch_size: 16  # REDUZIDO para limite 6GB VRAM
  normalize_embeddings: true
  device: "cuda"

  use_cache: true
  cache_dir: "cache/02_rtptorrent"

# Alias for backward compatibility
semantic:
  model_name: "sentence-transformers/all-mpnet-base-v2"
  embedding_dim: 768
  combined_embedding_dim: 1536
  max_length: 128
  batch_size: 16  # REDUZIDO para limite 6GB VRAM

# Structural Features (more important for RTPTorrent)
structural:
  extractor:
    recent_window: 5
    min_history: 2
    cache_path: "cache/02_rtptorrent/structural_features.pkl"
  input_dim: 6

# Cold-Start Regressor Configuration
# Uses MLP to predict structural features for TCs without history
coldstart:
  enabled: true
  cache_path: "cache/02_rtptorrent/coldstart_regressor.pkl"
  hidden_dims: [512, 256, 128]
  dropout: 0.2
  learning_rate: 0.001
  weight_decay: 0.0001
  batch_size: 64
  num_epochs: 100
  patience: 10

# Multi-Edge Graph
graph:
  build_graph: true
  use_multi_edge: true

  edge_types:
    - co_failure
    - co_success
    - semantic

  edge_weights:
    co_failure: 1.0
    co_success: 0.5
    semantic: 0.3

  min_co_occurrences: 1
  weight_threshold: 0.05

  semantic_top_k: 10
  semantic_threshold: 0.7

  cache_path: "cache/02_rtptorrent/multi_edge_graph.pkl"
  type: "co_failure"

  # Inductive mode: only train TCs in graph

# Model Architecture
model:
  type: "dual_stream"
  num_classes: 2

  semantic:
    input_dim: 1536
    hidden_dim: 256
    num_layers: 2
    dropout: 0.15
    activation: "gelu"

  structural:
    input_dim: 6
    hidden_dim: 64
    num_layers: 2
    dropout: 0.15
    activation: "gelu"

  gnn:
    type: "GAT"
    hidden_dim: 128
    num_layers: 2
    num_heads: 4
    dropout: 0.2
    activation: "elu"

  fusion:
    input_dim: 384
    hidden_dim: 256
    num_layers: 2
    dropout: 0.2
    activation: "gelu"

  classifier:
    input_dim: 256
    hidden_dim: 128
    num_classes: 2
    dropout: 0.3

# Training Configuration
# NOTE: Current processed dataset is very small (514 samples, 1 project)
# Need to reprocess with more projects for meaningful training
training:
  num_epochs: 50
  epochs: 50
  batch_size: 8  # REDUZIDO para limite 6GB VRAM
  learning_rate: 0.0001  # Slightly higher LR
  weight_decay: 0.0001

  optimizer: "adamw"
  scheduler:
    type: "cosine"
    eta_min: 0.000001
  warmup_epochs: 5

  gradient_clip: 1.0
  accumulation_steps: 1

  early_stopping:
    patience: 15
    min_delta: 0.001
    monitor: "val_f1_macro"
    mode: "max"

  sampling:
    use_balanced_sampling: true
    minority_weight: 1.0
    majority_weight: 0.1  # Adjust based on actual class ratio

  loss:
    type: "weighted_focal"
    focal_alpha: 0.75
    focal_gamma: 2.5  # Slightly lower gamma
    label_smoothing: 0.0

# Legacy loss config
loss:
  type: "weighted_focal"
  focal_alpha: 0.75
  focal_gamma: 2.5
  label_smoothing: 0.0

# Evaluation
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_macro"
    - "f1_weighted"
    - "auprc_macro"
    - "auroc"

  threshold_search:
    enabled: true
    range: [0.01, 0.99]
    step: 0.01
    optimize_for: "f1_macro"

# Ranking Configuration
ranking:
  method: "probability"
  reverse: true

  apfd_calculation:
    enabled: true
    fault_column: "verdict"
    fault_value: "Fail"

# System Configuration
# OPTIMIZED FOR RTX 4060 (8GB VRAM)
system:
  device: "cuda"
  num_workers: 2  # REDUCED from 4 - prevents memory pressure
  pin_memory: true
  use_amp: true  # ENABLED - reduces VRAM usage by ~40%

  deterministic: true
  benchmark: false

hardware:
  device: "cuda"
  num_workers: 2  # REDUCED - matches system config

# Logging and Checkpointing
logging:
  level: "INFO"
  log_dir: "logs"
  tensorboard: false

checkpoint:
  save_best: true
  save_last: true
  monitor: "val_f1_macro"
  mode: "max"

output:
  results_dir: "results/experiment_rtptorrent"
  save_predictions: true
  save_rankings: true
  save_apfd: true
  save_plots: true
