# üéØ ESTRAT√âGIA: Experimentos 04 - Abordagem Conservadora

## üìä SITUA√á√ÉO ATUAL

Todos os experimentos anteriores **colapsaram**:

| Exp | T√©cnicas Usadas | Resultado |
|-----|----------------|-----------|
| 01 | Focal (0.25, 2.0) | ‚ùå Colapso ‚Üí Pass (baseline) |
| 02 | Focal (0.75, 3.0) + Weights + Sampling (20:1) | ‚ùå Colapso ‚Üí Fail |
| 03 | Focal (0.25, 2.0) + Weights + Sampling (5:1) | ‚ùå Colapso ‚Üí Fail |

**DIAGN√ìSTICO**: Combinar m√∫ltiplas t√©cnicas de rebalanceamento causa **overengineering** e colapso.

**SOLU√á√ÉO**: Testar t√©cnicas **ISOLADAMENTE**.

---

## üéØ EXPERIMENTOS 04: TESTE ISOLADO

### Experimento 04a: WEIGHTED CE APENAS ‚≠ê RECOMENDADO

**Configura√ß√£o**: `configs/experiment_04a_weighted_ce_only.yaml`

```yaml
Loss: Weighted Cross-Entropy
  - Class weights autom√°ticos [19.13, 0.51]
  - SEM Focal Loss
  - SEM Balanced Sampling

Model: Simplificado
  - GAT: 1 layer, 2 heads (de 2 layers, 4 heads)
  - Dropout: 0.1-0.2 (de 0.15-0.3)
  - LR: 3e-5 (de 5e-5)

Graph: Menos denso
  - semantic_top_k: 5 (de 10)
  - semantic_threshold: 0.75 (de 0.7)
```

**Por qu√™ come√ßar aqui?**
- ‚úÖ Mais simples e est√°vel
- ‚úÖ Amplamente usado em produ√ß√£o
- ‚úÖ Apenas 1 mecanismo de rebalanceamento
- ‚úÖ Menos hiper-par√¢metros

**Expectativa**:
- F1 Macro: **0.30-0.40** (vs 0.025 atual)
- Recall Not-Pass: **0.20-0.40** (vs 1.00 colapsado)
- Recall Pass: **0.95-0.98** (vs 0.00 colapsado)
- **AMBAS classes preditas** (sem colapso)

---

### Experimento 04b: FOCAL LOSS APENAS

**Configura√ß√£o**: `configs/experiment_04b_focal_only.yaml`

```yaml
Loss: Focal Loss
  - focal_alpha: 0.5 (moderado)
  - focal_gamma: 2.0
  - use_class_weights: false  ‚Üê SEM weights extras
  - SEM Balanced Sampling

Model: Simplificado (igual 04a)
```

**Quando usar?**
- Se 04a falhar ou tiver F1 < 0.30
- Focal pode focar melhor em hard examples
- Alternativa ao class weights

**Expectativa**:
- F1 Macro: **0.25-0.35**
- Pode precisar ajuste de alpha (0.3-0.7)

---

## üöÄ PLANO DE EXECU√á√ÉO

### Passo 1: Executar 04a (PRIMEIRA PRIORIDADE)

```bash
# Limpar cache de graph (usar novo semantic_top_k=5)
rm cache/multi_edge_graph.pkl

# Executar
./venv/bin/python main.py --config configs/experiment_04a_weighted_ce_only.yaml
```

**Monitorar durante execu√ß√£o**:
1. **Build graph**: Densidade deve ser ~10-15% (n√£o 21%)
2. **Epoch 1**: Ver se prediz ambas classes
3. **Epoch 5**: Ver se m√©tricas est√£o melhorando
4. **Epoch 10**: F1 > 0.20?

**Crit√©rios de SUCESSO**:
- [ ] Val F1 Macro **varia** entre √©pocas (n√£o constante!)
- [ ] Val Accuracy **varia** (n√£o 2.8% fixo)
- [ ] Confusion matrix mostra **ambas classes preditas**
- [ ] F1 Macro > 0.30 no final
- [ ] Recall Pass > 0.95

**Crit√©rios de FALHA** (parar experimento):
- [ ] Val F1 = 0.0275 em todas √©pocas (colapso)
- [ ] Prediz s√≥ 1 classe (0% diversity)
- [ ] Loss n√£o converge (> 0.15 ap√≥s 10 √©pocas)

### Passo 2: An√°lise dos Resultados

#### Se 04a FUNCIONAR ‚úÖ

**Pr√≥ximos passos**:
1. Adicionar threshold optimization (j√° implementado)
2. Tentar adicionar **1 t√©cnica por vez**:
   - Exp 05a: Weighted CE + Sampling LEVE (2:1)
   - Exp 05b: Weighted CE + Focal LEVE (alpha=0.1, gamma=1.5)
3. Comparar F1 antes/depois de cada adi√ß√£o

#### Se 04a FALHAR ‚ùå

**Alternativas**:
1. Executar **Exp 04b** (Focal apenas)
2. Se 04b tamb√©m falhar:
   - SMOTE agressivo (oversample at√© 1:1)
   - Two-stage training
   - Simplificar modelo ainda mais (MLP sem GAT)
   - Considerar problema intrat√°vel

---

## üìä M√âTRICAS ESPERADAS (REALISTAS)

Para imbalance **37:1**, literatura mostra:

| M√©trica | Baseline | M√≠nimo | Alvo | Excelente |
|---------|----------|--------|------|-----------|
| **F1 Macro** | 0.10 | 0.25 | **0.35** | 0.50 |
| **Recall Not-Pass** | 0.00 | 0.15 | **0.30** | 0.50 |
| **Precision Not-Pass** | 0.00 | 0.20 | **0.35** | 0.50 |
| **Recall Pass** | 1.00 | 0.95 | **0.97** | 0.98 |
| **APFD** | 0.61 | 0.55 | **0.60** | 0.65 |

**Nota**: Nossas metas originais (F1=0.50-0.55) eram **otimistas demais** para ratio 37:1!

---

## üîß MODIFICA√á√ïES APLICADAS

### 1. Model Simplificado

**ANTES** (Exp 01-03):
```yaml
gnn:
  num_layers: 2
  num_heads: 4
  dropout: 0.2

classifier:
  dropout: 0.3
```

**AGORA** (Exp 04a/04b):
```yaml
gnn:
  num_layers: 1  # ‚Üì 50% par√¢metros
  num_heads: 2   # ‚Üì 50% par√¢metros
  dropout: 0.1   # ‚Üì regulariza√ß√£o

classifier:
  dropout: 0.2   # ‚Üì regulariza√ß√£o
```

**Raz√£o**: Modelo complexo demais para 1,323 samples minority

### 2. Graph Menos Denso

**ANTES**:
```yaml
semantic_top_k: 10
semantic_threshold: 0.7
Density: 21.36%
```

**AGORA**:
```yaml
semantic_top_k: 5      # ‚Üì 50% edges
semantic_threshold: 0.75  # ‚Üë mais seletivo
Expected density: 10-15%
```

**Raz√£o**: Graph muito denso pode propagar ru√≠do

### 3. Learning Rate Reduzido

**ANTES**: 5e-5
**AGORA**: 3e-5 (40% redu√ß√£o)

**Raz√£o**: LR alto pode causar instabilidade com imbalance

### 4. Early Stopping Mais Paciente

**ANTES**: patience=12
**AGORA**: patience=15

**Raz√£o**: Dar mais tempo para convergir

---

## ‚ö†Ô∏è SINAIS DE ALERTA

Durante treinamento, **PARAR** se ver:

1. **Colapso detectado**:
   - Val Acc = 0.0283 ou 0.9717 (constante)
   - Val F1 = 0.0275 ou 0.9800 (constante)
   - Classification report: 1 classe com recall=0%

2. **Loss divergente**:
   - Train loss > 0.20 ap√≥s 5 √©pocas
   - Val loss aumentando consistentemente

3. **Gradientes explodindo**:
   - Loss = NaN ou Inf
   - Warnings de gradient clipping

Se qualquer um ocorrer: **CTRL+C e ajustar config**

---

## üìã CHECKLIST DE EXECU√á√ÉO

### Antes de executar
- [ ] Cache de graph limpo (`rm cache/multi_edge_graph.pkl`)
- [ ] GPU dispon√≠vel (`nvidia-smi`)
- [ ] Config correto escolhido (04a recomendado)

### Durante execu√ß√£o (monitorar)
- [ ] Graph building: Edges ~200K-300K (n√£o 588K)
- [ ] Epoch 1: Ambas classes preditas?
- [ ] Epoch 5: Val F1 > 0.15?
- [ ] Epoch 10: Val F1 > 0.25?

### Ap√≥s execu√ß√£o
- [ ] Test F1 Macro > 0.30?
- [ ] Recall Pass > 0.95?
- [ ] Recall Not-Pass > 0.20?
- [ ] APFD > 0.55?
- [ ] Confusion matrix balanceada?

---

## üéØ DECIS√ÉO AP√ìS EXP 04a

### Cen√°rio A: SUCESSO (F1 > 0.30, sem colapso)

**A√ß√£o**: Gradualmente adicionar t√©cnicas
1. Threshold optimization
2. Sampling leve (2:1)
3. Focal leve (alpha=0.1)

**Objetivo**: Chegar em F1 ~ 0.40-0.45

### Cen√°rio B: PARCIAL (F1 = 0.20-0.30, sem colapso)

**A√ß√£o**:
- Aceitar como baseline
- Tentar Exp 04b (Focal)
- Considerar SMOTE

**Objetivo**: Melhorar para F1 ~ 0.30-0.35

### Cen√°rio C: FALHA (F1 < 0.20 ou colapso)

**A√ß√£o**:
- Executar Exp 04b
- Se tamb√©m falhar, considerar:
  - SMOTE agressivo
  - Two-stage training
  - Aceitar limita√ß√£o do problema

---

## üí° SE TUDO FALHAR

### √öltima Linha de Defesa

1. **Treinar apenas para ranking** (n√£o classifica√ß√£o):
   - Usar loss de ranking (Triplet, ArcFace)
   - Focar em APFD (j√° razo√°vel)
   - Aceitar que classifica√ß√£o √© intrat√°vel

2. **Ensemble de modelos simples**:
   - 5 modelos com seeds diferentes
   - Voting para classifica√ß√£o
   - M√©dia de probabilities para ranking

3. **Aceitar limita√ß√£o**:
   - Ratio 37:1 pode ser **limite do trat√°vel**
   - APFD=0.60 √© **aceit√°vel** para ranking
   - Classifica√ß√£o pode n√£o ser necess√°ria

---

## ‚úÖ RESUMO EXECUTIVO

**PROBLEMA**: Todos experimentos colapsam por overengineering

**SOLU√á√ÉO**: Teste isolado de t√©cnicas simples

**PR√ìXIMA A√á√ÉO**:

```bash
# Limpar cache
rm cache/multi_edge_graph.pkl

# Executar Exp 04a
./venv/bin/python main.py --config configs/experiment_04a_weighted_ce_only.yaml
```

**TEMPO ESTIMADO**: 2-3 horas

**CRIT√âRIO SUCESSO**: F1 > 0.30, ambas classes preditas, sem colapso

**SE FUNCIONAR**: Adicionar t√©cnicas gradualmente

**SE FALHAR**: Tentar Exp 04b ou abordagens alternativas

---

**Boa sorte! üçÄ**
