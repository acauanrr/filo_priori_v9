# Fix: STEP 6 Data Loader Scope Issue

**Data**: 2025-11-07
**Status**: ‚úÖ **CORRIGIDO**

---

## üî¥ PROBLEMA IDENTIFICADO

Durante a execu√ß√£o do `experiment_v8_weighted_ce`, o STEP 6 (processamento do test.csv completo) falhou:

```
ERROR:__main__:
‚ùå ERROR processing full test.csv: name 'data_loader' is not defined
ERROR:__main__:   Continuing with split test results only...
Traceback (most recent call last):
  File "/home/acauanribeiro/iats/filo_priori_v8/main_v8.py", line 652, in main
    test_df_full = data_loader.load_full_test_dataset()
                   ^^^^^^^^^^^
NameError: name 'data_loader' is not defined. Did you mean: 'DataLoader'?
```

**Consequ√™ncia**: Processou apenas 64 builds do split de teste ao inv√©s dos 277 builds esperados do test.csv completo.

---

## üîç CAUSA RAIZ

O objeto `data_loader` (e outros como `encoder`, `text_processor`, `extractor`) foram criados dentro da fun√ß√£o `prepare_data()` mas **n√£o foram retornados**. Quando o STEP 6 tentou us√°-los, estavam fora de escopo.

```python
# prepare_data() linha 84
def prepare_data(config: Dict, sample_size: int = None):
    data_loader = DataLoader(config)  # Criado aqui
    encoder = SemanticEncoder(...)
    text_processor = TextProcessor()
    extractor = StructuralFeatureExtractor(...)
    # ... c√≥digo ...
    return train_data, val_data, test_data, ...  # ‚ùå N√£o retornava data_loader!

# main() linha 652
def main(args):
    # ... c√≥digo ...
    test_df_full = data_loader.load_full_test_dataset()  # ‚ùå Erro: data_loader n√£o existe!
```

---

## ‚úÖ SOLU√á√ÉO IMPLEMENTADA

### 1. Atualizar `prepare_data()` para Retornar Objetos Necess√°rios

**Linha 272** (antes linha 266):
```python
return (train_data, val_data, test_data, graph_builder, edge_index, edge_weights,
        class_weights, data_loader, encoder, text_processor, extractor)
        #            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        #            ADICIONADO: 4 objetos necess√°rios para STEP 6
```

### 2. Atualizar Docstring

**Linhas 75-77**:
```python
Returns:
    Tuple of (train_data, val_data, test_data, graph_builder, edge_index, edge_weights,
              class_weights, data_loader, encoder, text_processor, extractor)
```

### 3. Atualizar `main()` para Receber Objetos

**Linhas 452-453**:
```python
(train_data, val_data, test_data, graph_builder, edge_index, edge_weights,
 class_weights, data_loader, encoder, text_processor, extractor) = prepare_data(config, args.sample_size)
```

---

## üöÄ IMPACTO DA CORRE√á√ÉO

### Antes (com erro)
```
STEP 6: PROCESSING FULL TEST.CSV FOR FINAL APFD
‚ùå ERROR: name 'data_loader' is not defined
‚ö†Ô∏è  WARNING: Expected 277 builds but got 64
```

### Depois (esperado)
```
STEP 6: PROCESSING FULL TEST.CSV FOR FINAL APFD
6.1: Loading FULL test.csv...
‚úÖ Loaded full test.csv:
   Total samples: ~180K
   Total builds: ~1000+
   Builds with 'Fail': 277

6.2: Generating semantic embeddings for full test set...
‚úÖ Generated embeddings: (180K, 1024)

6.3: Extracting structural features for full test set...
‚úÖ Extracted features: (180K, 6)
‚úÖ Imputed 50123 unknown tests

6.4: Generating predictions on full test set...
‚úÖ Generated predictions: 180K samples

6.5: Generating prioritized CSV (FULL test.csv)...
‚úÖ Saved: prioritized_test_cases_FULL_testcsv.csv

6.6: Calculating APFD per build (FULL test.csv)...
‚úÖ SUCCESS: Found exactly 277 builds with failures!
üìä Mean APFD: 0.XXXX (across 277 builds)  ‚Üê M√âTRICA FINAL!
```

---

## üìù VALIDA√á√ÉO

### 1. Verificar Sintaxe
```bash
python -m py_compile main_v8.py
# ‚úÖ Sem erros de sintaxe
```

### 2. Executar Novamente
```bash
python main_v8.py --config configs/experiment_v8_weighted_ce.yaml --device cuda
```

### 3. Verificar Resultados
```bash
# Deve ter 277 builds (278 linhas com header)
wc -l results/experiment_v8_weighted_ce/apfd_per_build_FULL_testcsv.csv

# Deve mostrar 277 builds
grep "total_builds" results/experiment_v8_weighted_ce/tmux-buffer.txt

# Deve ter ~180K linhas (+ header)
wc -l results/experiment_v8_weighted_ce/prioritized_test_cases_FULL_testcsv.csv
```

---

## üéØ PR√ìXIMA A√á√ÉO

### Executar Novamente com Corre√ß√£o

```bash
# O modelo J√Å EST√Å TREINADO! (best_model.pt existe)
# Mas precisa re-rodar STEP 6 para processar test.csv completo

python main_v8.py --config configs/experiment_v8_weighted_ce.yaml --device cuda
```

**Nota**: Se quiser APENAS re-rodar STEP 6 sem re-treinar:
1. O c√≥digo vai carregar automaticamente `best_model.pt` se existir
2. Pode pular epochs j√° treinadas se implementar checkpoint loading
3. Ou criar script separado para processar apenas test.csv

---

## üìä RESULTADOS ESPERADOS

Com a corre√ß√£o, o STEP 6 deve processar com sucesso:

| M√©trica | Valor Esperado |
|---------|----------------|
| Total test.csv samples | ~180,000 |
| Total builds | ~1000+ |
| **Builds com Fail** | **277** ‚úÖ |
| Prioritized CSV | ‚úÖ Criado |
| APFD per build | ‚úÖ 277 builds |
| Mean APFD (final) | 0.55-0.60 |

---

## ‚úÖ STATUS

- [x] Problema identificado
- [x] Causa raiz analisada
- [x] Solu√ß√£o implementada
- [x] Sintaxe validada
- [ ] Re-execu√ß√£o para valida√ß√£o final

**Pr√≥xima A√ß√£o**: Executar `python main_v8.py --config configs/experiment_v8_weighted_ce.yaml --device cuda`

---

**Corre√ß√£o completa em**: `main_v8.py` (linhas 76-77, 272, 452-453)
