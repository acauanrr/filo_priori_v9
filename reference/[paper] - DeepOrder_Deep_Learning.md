A seguir estÃ¡ uma explicaÃ§Ã£o completa, clara e em PortuguÃªs-BR, sobre o paper â€œDeepOrder: Deep Learning for Test Case Prioritization in Continuous Integration Testingâ€, com base no texto e figuras do documento 

[paper] - DeepOrder_Deep_Learniâ€¦

.

ğŸ“˜ Explicando o Paper â€œDeepOrderâ€

O artigo apresenta DeepOrder, um modelo de deep learning criado para priorizaÃ§Ã£o de casos de teste em pipelines de Continuous Integration (CI). Ele resolve limitaÃ§Ãµes importantes de mÃ©todos anteriores â€” principalmente velocidade, escalabilidade e capacidade de usar histÃ³rico longo de execuÃ§Ãµes.

A seguir, explico o paper por seÃ§Ãµes, de forma didÃ¡tica.

1. Contexto e MotivaÃ§Ã£o

(SeÃ§Ã£o I â€“ IntroduÃ§Ã£o)

Em pipelines CI, toda mudanÃ§a no cÃ³digo dispara dezenas ou centenas de testes. PorÃ©m:

â— Nem todos os testes cabem dentro do tempo limitado de cada ciclo CI.

ğŸ¯ O objetivo Ã© rodar primeiro os testes com maior chance de falhar, para detectar bugs mais cedo.

MÃ©todos existentes:

MÃ©todo	Problema
ROCKET	Funciona bem, mas fica extremamente lento com grandes histÃ³ricos.
RETECS (Reinforcement Learning)	Usa sÃ³ 4 ciclos de histÃ³rico; demora muito para treinar.
Outros ML	Usam poucos dados, nÃ£o escalam, ou ignoram tempo de execuÃ§Ã£o.

Resultado:
â¡ï¸ A priorizaÃ§Ã£o fica subÃ³tima e lenta.

DeepOrder surge para resolver isso.

2. DefiniÃ§Ã£o do Problema

(SeÃ§Ã£o II)

O objetivo Ã© ordenar casos de teste T de forma que:

Detectem falhas o mais cedo possÃ­vel

Caibam dentro de um orÃ§amento de tempo

Cada teste tem:

histÃ³rico de execuÃ§Ãµes (pass/fail/not executed)

duraÃ§Ã£o mÃ©dia

momento da Ãºltima execuÃ§Ã£o

mudanÃ§as no comportamento (quantas vezes alternou entre passâ†’fail)

Os autores definem uma funÃ§Ã£o de prioridade:

ğ‘
(
ğ‘¡
ğ‘–
)
=
âˆ‘
ğ‘—
=
1
ğ‘š
ğ‘¤
ğ‘—
â‹…
max
â¡
(
ğ¸
ğ‘†
(
ğ‘–
,
ğ‘—
)
,
0
)
p(t
i
	â€‹

)=
j=1
âˆ‘
m
	â€‹

w
j
	â€‹

â‹…max(ES(i,j),0)

onde:

ES(i,j) âˆˆ {1 = falhou, 0 = passou, -1 = nÃ£o rodou}

wâ‚– = peso maior para ciclos recentes

Essa prioridade real Ã© usada como label para treinar o modelo.

3. Como o DeepOrder Funciona

(SeÃ§Ã£o III, Figuras 1 e 2)

ğŸ” 3.1 Pipeline Geral (Figura 1)

A pipeline Ã©:

Extrair histÃ³rico de execuÃ§Ãµes de CI

Extrair features (statuses, duraÃ§Ã£o, mudanÃ§as, timestamp)

Balacear dataset com SMOGN (porque falhas sÃ£o muito raras)

Treinar uma rede neural

Usar a rede para prever prioridades de testes futuros

ğŸ§  3.2 Arquitetura da Rede Neural (Figura 2)

A rede Ã© simples e eficiente:

Entrada: 14 features

3 camadas escondidas: 10 â†’ 20 â†’ 15 neurÃ´nios

AtivaÃ§Ã£o: Mish (melhor que ReLU)

SaÃ­da: 1 nÃºmero real = prioridade

Loss: MSE

Optimizer: Adam

Treino atÃ© MSE < 0.0001

O modelo prioriza casos como um regressor, e nÃ£o como classificador.

4. Datasets e PreparaÃ§Ã£o

(SeÃ§Ã£o IV)

O DeepOrder foi avaliado em:

Cisco (caso real principal)

ABB Robotics â€“ Paint Control

ABB Robotics â€“ IOF/ROL

Google GSDTSR (12 milhÃµes de execuÃ§Ãµes)

Problema:
ğŸ”´ ProporÃ§Ã£o de falhas Ã© extremamente baixa
Exemplo (Tabela II):

Cisco: 0.43% de falhas

Google: 0.0025% de falhas

SoluÃ§Ã£o:
âœ”ï¸ SMOGN para gerar dados sintÃ©ticos em regressÃ£o (nÃ£o SMOTE â€œclÃ¡ssicoâ€)

Isso forÃ§a o modelo a aprender melhor os casos realmente crÃ­ticos.

5. MÃ©tricas de AvaliaÃ§Ã£o

(Tabela IV)

As mÃ©tricas principais sÃ£o:

ğŸ”¹ APFD

Average Percentage of Faults Detected
â†’ mede quÃ£o cedo as falhas sÃ£o detectadas

ğŸ”¹ NAPFD

VersÃ£o normalizada, usada para comparaÃ§Ãµes justas

ğŸ”¹ MÃ©tricas de Tempo

Incluem:

FT (First fault time)

LT (Last fault time)

TT (Total runtime do algoritmo)

RT (Tempo para priorizar)

AT (Avg. time to detect all faults)

Essas mÃ©tricas sÃ£o crÃ­ticas porque o objetivo Ã© acelerar CI.

6. Resultados Experimentais

(SeÃ§Ã£o V, Tabelas e Figuras)

ğŸŸ¦ 6.1 RQ1 â€“ DeepOrder detecta mais falhas?

Sim.

ComparaÃ§Ã£o direta com RETECS-N (Figura 4):

DeepOrder vence em 3/4 datasets em NAPFD

Ã‰ muito mais estÃ¡vel (menos outliers)

RETECS sÃ³ ganha em um dataset (Paint Control)

ğŸŸ© 6.2 RQ2 â€“ DeepOrder Ã© mais rÃ¡pido?

Sim â€” e MUITO.

Figura 5:
DeepOrder supera ROCKET nas mÃ©tricas FT, LT, AT.

Figura 6:
Em datasets grandes (Google, com 12 milhÃµes de execuÃ§Ãµes):

DeepOrder Ã© 70Ã— mais rÃ¡pido que ROCKET para priorizar

DeepOrder leva 13 s vs. milhares de segundos do ROCKET

Em tempo total (TT), DeepOrder leva 0.5 h, RETECS leva 25 horas

ğŸŸ¨ 6.3 RQ3 â€“ Usar histÃ³rico maior melhora o resultado?

Sim â€” e esse Ã© um dos achados mais importantes do paper.

A Figura 7 mostra:

â¡ï¸ Usar mais de 4 ciclos melhora APFD e NAPFD em TODOS os datasets.

Isso contradiz a crenÃ§a do RETECS, que limitava histÃ³rico por questÃµes de custo.

ğŸŸ§ 6.4 RQ4 â€“ O modelo prevÃª prioridades com precisÃ£o?

Sim.

Valores de MSE da Tabela VI:

Cisco: 0.000038

Paint Control: 0.000123

IOF/ROL: 0.000001

Google: 0.000031

Muito baixos para regressÃ£o.

O grÃ¡fico de loss (Figura 9) mostra convergÃªncia estÃ¡vel.

7. DiscussÃ£o e Trabalhos Relacionados

(SeÃ§Ã£o VI e VII)

Por que o DeepOrder funciona tÃ£o bem?

ML supervisionado aprende rÃ¡pido

NÃ£o tem o custo gigantesco de RL

Pode usar histÃ³rico ilimitado

Escala bem para milhÃµes de execuÃ§Ãµes

Tem arquitetura leve (apenas 631 parÃ¢metros)

LimitaÃ§Ãµes:

NÃ£o considera flaky tests

NÃ£o usa informaÃ§Ã£o do cÃ³digo

Ignora testes nÃ£o executados

NÃ£o lida com mudanÃ§as estruturais no projeto

8. ConclusÃ£o

(SeÃ§Ã£o VII)

DeepOrder oferece:

âœ”ï¸ Melhor detecÃ§Ã£o de falhas do que RETECS e que prÃ¡ticas da indÃºstria
âœ”ï¸ Muito mais rÃ¡pido (atÃ© 70Ã—)
âœ”ï¸ Aproveita histÃ³rico longo
âœ”ï¸ Simples de treinar e implantar
âœ”ï¸ Funciona com grandes datasets reais (Google, Cisco, ABB)

Ele demonstra que deep learning supervisionado, mesmo simples, Ã© mais eficaz que tÃ©cnicas mais complexas (reinforcement learning, heurÃ­sticas, etc.) para priorizaÃ§Ã£o de testes.