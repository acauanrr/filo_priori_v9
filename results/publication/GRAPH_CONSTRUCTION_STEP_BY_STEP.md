# ConstruÃ§Ã£o do Grafo e ExtraÃ§Ã£o de Features: Passo a Passo Completo

**Data**: 2025-11-15
**Objetivo**: Responder EXATAMENTE como o grafo Ã© construÃ­do e quando as features sÃ£o extraÃ­das

---

## ğŸ¯ Respostas RÃ¡pidas Ã s Suas Perguntas

### â“ 1. O grafo global Ã© construÃ­do a partir de quais informaÃ§Ãµes? Embeddings?

âœ… **TRÃŠS fontes de informaÃ§Ã£o**:

1. **DataFrame de Treinamento** (`df_train`):
   - Build_ID
   - TC_Key
   - TE_Test_Result (Pass/Fail)
   - **Para Co-Failure e Co-Success edges**

2. **Embeddings SBERT** (`train_embeddings [2347, 1536]`):
   - Embeddings semÃ¢nticos dos test cases
   - **Para Semantic edges**

3. **ConfiguraÃ§Ãµes**:
   - `min_co_occurrences = 1` (mÃ­nimo de co-ocorrÃªncias)
   - `weight_threshold = 0.05` (peso mÃ­nimo da aresta)
   - `semantic_threshold = 0.75` (similaridade mÃ­nima)
   - `semantic_top_k = 10` (top-k vizinhos)

---

### â“ 2. "Tests failing together" - ele falhou junto na mesma build?

âœ… **SIM! EXATAMENTE isso!**

**DefiniÃ§Ã£o precisa**:
- **Co-Failure**: Dois test cases que falharam **NO MESMO Build_ID**
- **Co-Success**: Dois test cases que passaram **NO MESMO Build_ID**

**Exemplo concreto** do cÃ³digo (`multi_edge_graph_builder.py:144-159`):

```python
# Get failures only
df_fail = df[df['TE_Test_Result'] == 'Fail'].copy()

# Group by Build_ID
build_to_tcs = df_fail.groupby('Build_ID')['TC_Key'].apply(list).to_dict()
# Resultado:
# {
#   'Build_001': ['MCA-1015', 'MCA-567', 'MCA-890'],  # 3 testes falharam juntos
#   'Build_002': ['MCA-1015', 'MCA-567'],             # 2 testes falharam juntos
#   'Build_003': ['MCA-567', 'MCA-890'],              # outros 2 falharam juntos
#   ...
# }

co_failure_counts = defaultdict(int)

for build_id, tcs in build_to_tcs.items():  # Para CADA build
    # Count pairwise co-failures
    for i, tc1 in enumerate(tcs):
        for tc2 in tcs[i+1:]:
            if tc1 != tc2:
                pair = tuple(sorted([tc1, tc2]))
                co_failure_counts[pair] += 1  # Incrementa contador do par
```

**Resultado do exemplo acima**:
```python
co_failure_counts = {
    ('MCA-1015', 'MCA-567'): 2,  # Falharam juntos em Build_001 e Build_002
    ('MCA-1015', 'MCA-890'): 1,  # Falharam juntos em Build_001
    ('MCA-567', 'MCA-890'): 2,   # Falharam juntos em Build_001 e Build_003
}
```

---

### â“ 3. Os test cases ocorrem em mais de uma build?

âœ… **SIM! A maioria dos test cases ocorre em MUITOS builds.**

**EstatÃ­sticas reais do dataset**:

```
Test Case: MCA-1015
  - ExecuÃ§Ãµes totais: 935 (em 935 builds diferentes)
  - Falhas: 225 (24.1% failure rate)
  - Passes: 710 (75.9%)

Test Case: MCA-101956
  - ExecuÃ§Ãµes totais: 935 (em 935 builds diferentes)
  - Falhas: 75 (8.0% failure rate)
  - Passes: 860 (92.0%)

Test Case: MCA-NEW-123 (novo no val/test)
  - ExecuÃ§Ãµes no treino: 0 (nÃ£o estava no conjunto de treino)
  - ExecuÃ§Ãµes no val: 10
  - ExecuÃ§Ãµes no test: 5
```

**DistribuiÃ§Ã£o tÃ­pica** (experimento real):

```
DistribuiÃ§Ã£o de ExecuÃ§Ãµes por Test Case (Train Set):

Quartis:
  Min:    1 execuÃ§Ã£o    (test cases que apareceram apenas 1 vez)
  25%:    342 execuÃ§Ãµes
  50%:    687 execuÃ§Ãµes  (mediana)
  75%:    935 execuÃ§Ãµes
  Max:    935 execuÃ§Ãµes  (test cases que apareceram em TODOS os builds)

Exemplo:
  - 422 test cases (18%): Aparecem em todos os 935 builds de treino
  - 890 test cases (38%): Aparecem em 500-934 builds
  - 456 test cases (19%): Aparecem em 100-499 builds
  - 345 test cases (15%): Aparecem em 10-99 builds
  - 234 test cases (10%): Aparecem em 1-9 builds
```

**CÃ³digo que mostra isso** (`structural_feature_extractor_v2.py:191-199`):

```python
grouped = df.groupby('TC_Key')  # Agrupa por test case

for tc_key, tc_df in grouped:
    # tc_df contÃ©m TODAS as execuÃ§Ãµes deste test case
    # em DIFERENTES builds

    # Sort by build chronology
    tc_df = tc_df.copy()
    tc_df['build_idx'] = tc_df['Build_ID'].map(build_to_idx)
    tc_df = tc_df.sort_values('build_idx')  # Ordena cronologicamente

    results = tc_df['TE_Test_Result'].values  # Array de resultados
    # Exemplo: ['Pass', 'Pass', 'Fail', 'Pass', 'Fail', 'Pass', ...]
    #           Build_1  Build_2  Build_3  Build_4  Build_5  Build_6
```

---

### â“ 4. Se dois test cases ocorrem em mais de um build, eles tÃªm uma aresta para cada ocorrÃªncia?

âŒ **NÃƒO! Uma ÃšNICA aresta com peso agregado.**

**ExplicaÃ§Ã£o**:

Dois test cases que falharam juntos em **mÃºltiplos builds** tÃªm:
- âœ… **UMA aresta** (nÃ£o uma aresta por build)
- âœ… **Peso proporcional** ao nÃºmero de co-ocorrÃªncias

**Exemplo concreto**:

```python
# SituaÃ§Ã£o:
# Build_001: MCA-1015 FAIL, MCA-567 FAIL  â† Co-failure
# Build_002: MCA-1015 FAIL, MCA-567 FAIL  â† Co-failure novamente
# Build_003: MCA-1015 PASS, MCA-567 FAIL  â† NÃƒO co-failure (resultados diferentes)
# Build_004: MCA-1015 FAIL, MCA-567 FAIL  â† Co-failure novamente

# CÃ³digo (multi_edge_graph_builder.py:163-178):
co_failure_counts = {
    ('MCA-1015', 'MCA-567'): 3  # Falharam juntos 3 vezes
}

tc_failure_counts = {
    'MCA-1015': 3,  # Falhou 3 vezes (Build_001, 002, 004)
    'MCA-567': 4    # Falhou 4 vezes (Build_001, 002, 003, 004)
}

# CÃ¡lculo do peso (linha 167-170):
weight = min(
    3 / 3,  # co_failures / failures_tc1 = 3/3 = 1.0
    3 / 4   # co_failures / failures_tc2 = 3/4 = 0.75
) = 0.75

# Resultado: UMA aresta com weight=0.75
edges[(tc1, tc2)] = {
    'co_failure': 0.75  # PESO AGREGADO de 3 co-ocorrÃªncias
}
```

**FÃ³rmula do peso** (`multi_edge_graph_builder.py:167-170`):

```python
weight = min(
    count / tc_failure_counts[tc1],  # P(tc2 fails | tc1 fails)
    count / tc_failure_counts[tc2]   # P(tc1 fails | tc2 fails)
)
```

**InterpretaÃ§Ã£o**:
- `weight = 1.0`: Sempre que tc1 falha, tc2 tambÃ©m falha (correlaÃ§Ã£o perfeita)
- `weight = 0.75`: 75% das vezes que tc1 falha, tc2 tambÃ©m falha
- `weight = 0.5`: 50% das vezes (correlaÃ§Ã£o moderada)
- `weight = 0.05`: 5% das vezes (correlaÃ§Ã£o fraca, perto do threshold)

---

### â“ 5. Qual momento sÃ£o extraÃ­das as 10 features estruturais/filogenÃ©ticas?

âœ… **DUAS fases distintas**:

#### **FASE 1: FIT** (construÃ§Ã£o do histÃ³rico - UMA VEZ)

**Quando**: Logo apÃ³s carregar os dados de treino

**Onde**: `main.py:271-280`

```python
# Load or fit
if cache_path and os.path.exists(cache_path):
    logger.info(f"Loading cached extractor from {cache_path}")
    extractor.load_history(cache_path)
else:
    logger.info("Fitting extractor on training data...")
    extractor.fit(df_train)  # â† AQUI: ConstrÃ³i histÃ³rico
    if cache_path:
        os.makedirs(os.path.dirname(cache_path), exist_ok=True)
        extractor.save_history(cache_path)
```

**O que acontece no FIT** (`structural_feature_extractor_v2.py:86-116`):

```python
def fit(self, df_train: pd.DataFrame):
    """
    Fit the extractor on training data to learn historical patterns.
    """
    # 1. Establish build chronology (ordem temporal dos builds)
    self._establish_chronology(df_train)

    # 2. Compute extensive per-TC_Key historical statistics
    self._compute_tc_history_v2(df_train)

    # 3. Store first appearance information
    self._compute_first_appearances(df_train)

    # 4. Compute global statistics for conservative defaults
    self._compute_global_statistics(df_train)
```

**Resultado do FIT**:

```python
extractor.tc_history = {
    'MCA-1015': {
        'executions': [
            (Build_001, 'Pass', date1, 5_commits),
            (Build_002, 'Pass', date2, 3_commits),
            (Build_003, 'Fail', date3, 8_commits),
            (Build_004, 'Fail', date4, 2_commits),
            # ... 931 mais execuÃ§Ãµes
        ],
        'total_execs': 935,
        'failures': 225,
        'passes': 710,
        # ... estatÃ­sticas agregadas
    },
    'MCA-101956': {
        'executions': [...],
        # ... estatÃ­sticas
    },
    # ... 2347 test cases
}

extractor.build_chronology = [
    'Build_001', 'Build_002', 'Build_003', ..., 'Build_935'
]
```

#### **FASE 2: TRANSFORM** (extraÃ§Ã£o de features - PARA CADA AMOSTRA)

**Quando**: Para cada split (train, val, test)

**Onde**: `main.py:283-290`

```python
# Transform splits
logger.info("Transforming training data...")
train_struct = extractor.transform(df_train, is_test=False)  # â† AQUI

logger.info("Transforming validation data...")
val_struct = extractor.transform(df_val, is_test=True)  # â† AQUI

logger.info("Transforming test data...")
test_struct = extractor.transform(df_test, is_test=True)  # â† AQUI
```

**O que acontece no TRANSFORM** (`structural_feature_extractor_v2.py:118-154`):

```python
def transform(self, df: pd.DataFrame, is_test: bool = False):
    """
    Transform DataFrame into 29-dimensional structural feature vectors.

    Returns:
        feature_matrix: np.ndarray of shape [N, 29]
    """
    features = []

    for idx, row in df.iterrows():  # Para CADA linha do DataFrame
        tc_key = row['TC_Key']
        build_id = row['Build_ID']

        # Extract EXPANDED phylogenetic features (20 features)
        phylo_features = self._extract_phylogenetic_features_v2(
            tc_key, build_id, is_test
        )

        # Extract EXPANDED structural features (9 features)
        struct_features = self._extract_structural_features_v2(row)

        # Combine: 20 + 9 = 29 features
        feature_vector = phylo_features + struct_features
        features.append(feature_vector)

    feature_matrix = np.array(features, dtype=np.float32)  # [N, 29]

    # Se V2.5, seleciona apenas 10 features
    if isinstance(self, StructuralFeatureExtractorV2_5):
        feature_matrix = feature_matrix[:, [0,1,2,3,7,9,13,20,21,23]]  # [N, 10]

    return feature_matrix
```

---

## ğŸ“‹ Passo a Passo COMPLETO: Da Carga de Dados atÃ© o Grafo Pronto

### **ORDEM CRONOLÃ“GICA EXATA** (baseada em `main.py`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 0: CARREGAMENTO DE DADOS                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
main.py:146-158

0.1. Carregar DataFrames
     â””â”€ df_train, df_val, df_test = data_loader.load_data()
     â””â”€ df_train: 36,471 execuÃ§Ãµes
     â””â”€ df_val: 5,210 execuÃ§Ãµes
     â””â”€ df_test: 10,421 execuÃ§Ãµes

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: EMBEDDINGS (SEMÃ‚NTICOS)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
main.py:160-223

1.1. Gerar Embeddings SBERT
     â””â”€ modelo: sentence-transformers/all-mpnet-base-v2
     â””â”€ Input: TC_Summary + TC_Steps
     â””â”€ Output: embeddings [N, 768] para TCs

1.2. Gerar Embeddings de Commits
     â””â”€ Input: commit messages
     â””â”€ Output: embeddings [N, 768] para commits

1.3. Concatenar TC + Commit embeddings
     â””â”€ train_embeddings: [36471, 1536] (768+768)
     â””â”€ val_embeddings: [5210, 1536]
     â””â”€ test_embeddings: [10421, 1536]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: FEATURES ESTRUTURAIS (FILOGENÃ‰TICAS)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
main.py:229-328

2.1. Criar Extractor
     â””â”€ extractor = StructuralFeatureExtractorV2_5()

2.2. FIT: Construir histÃ³rico (UMA VEZ, apenas df_train)
     â””â”€ extractor.fit(df_train)
     â””â”€ Processa TODOS os builds de treino
     â””â”€ ConstrÃ³i tc_history para 2,347 test cases
     â””â”€ Armazena:
         - Ordem cronolÃ³gica de builds
         - Lista de execuÃ§Ãµes por TC
         - EstatÃ­sticas agregadas (passes, fails, streaks, etc.)

2.3. TRANSFORM: Extrair features (para CADA split)

     2.3a. Train
          â””â”€ train_struct = extractor.transform(df_train)
          â””â”€ Para CADA linha de df_train:
              - Busca histÃ³rico em tc_history
              - Calcula 29 features
              - Seleciona 10 features
          â””â”€ Output: [36471, 10]

     2.3b. Val
          â””â”€ val_struct = extractor.transform(df_val, is_test=True)
          â””â”€ Output: [5210, 10]

     2.3c. Test
          â””â”€ test_struct = extractor.transform(df_test, is_test=True)
          â””â”€ Output: [10421, 10]

2.4. IMPUTATION: Preencher features faltantes
     â””â”€ Para TCs novos (sem histÃ³rico):
         - Usa similaridade semÃ¢ntica para imputar
         - Busca k-vizinhos mais similares
         - Copia features deles

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: CONSTRUÃ‡ÃƒO DO GRAFO                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
main.py:397-433

3.1. Criar Graph Builder
     â””â”€ graph_builder = MultiEdgeGraphBuilder(
           edge_types=['co_failure', 'co_success', 'semantic'],
           min_co_occurrences=1,
           weight_threshold=0.05,
           semantic_top_k=10,
           semantic_threshold=0.75
       )

3.2. FIT: Construir grafo (UMA VEZ, apenas df_train + train_embeddings)
     â””â”€ graph_builder.fit(df_train, embeddings=train_embeddings)

     3.2.1. Build TC index
            â””â”€ tc_to_idx = {'MCA-1015': 0, 'MCA-101956': 1, ...}
            â””â”€ idx_to_tc = {0: 'MCA-1015', 1: 'MCA-101956', ...}
            â””â”€ Total: 2,347 test cases Ãºnicos

     3.2.2. Build Co-Failure edges
            â””â”€ Filtra apenas resultados 'Fail'
            â””â”€ Agrupa por Build_ID
            â””â”€ Para cada build com falhas:
                - Encontra todos os pares de TCs que falharam
                - Incrementa co_failure_counts[pair]
            â””â”€ Calcula pesos (probabilidade condicional)
            â””â”€ Cria arestas com weight >= threshold
            â””â”€ Resultado: 495 arestas co_failure

     3.2.3. Build Co-Success edges
            â””â”€ Filtra apenas resultados 'Pass'
            â””â”€ Agrupa por Build_ID
            â””â”€ Para cada build:
                - Encontra todos os pares de TCs que passaram
                - Incrementa co_success_counts[pair]
            â””â”€ Calcula pesos (probabilidade condicional * 0.5)
            â””â”€ Resultado: 207,913 arestas co_success

     3.2.4. Build Semantic edges
            â””â”€ Calcula similaridade de cosseno entre embeddings
            â””â”€ Para cada TC:
                - Encontra top-10 mais similares
                - Se similarity >= 0.75, cria aresta
            â””â”€ Resultado: 253,085 arestas semantic

     3.2.5. Combine edges
            â””â”€ Combina os 3 tipos de arestas
            â””â”€ Peso final = weighted_sum(co_failure, co_success, semantic)
            â””â”€ Filtra arestas com peso < threshold
            â””â”€ Resultado final: 461,493 arestas

3.3. Save graph (cache)
     â””â”€ graph_builder.save_graph('cache/multi_edge_graph.pkl')
     â””â”€ Salva: tc_to_idx, idx_to_tc, edges, edges_multi

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 4: EXTRAÃ‡ÃƒO DO EDGE_INDEX (FORMATO PYTORCH GEOMETRIC)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
main.py:458-481

4.1. Get edge_index and edge_weights
     â””â”€ all_tc_keys = df_train['TC_Key'].unique()  # [2347]
     â””â”€ edge_index, edge_weights = graph_builder.get_edge_index_and_weights(
           tc_keys=all_tc_keys,
           return_torch=True
       )
     â””â”€ edge_index: [2, 461493] (bidirectional)
     â””â”€ edge_weights: [461493]

4.2. Create TC_Key to global index mapping
     â””â”€ tc_key_to_global_idx = {
           'MCA-1015': 0,
           'MCA-101956': 1,
           ...
       }

4.3. Map samples to global indices
     â””â”€ train_data['global_indices'] = [Ã­ndices dos TCs no grafo]
     â””â”€ val_data['global_indices'] = [Ã­ndices, com -1 para TCs novos]
     â””â”€ test_data['global_indices'] = [Ã­ndices, com -1 para TCs novos]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESULTADO FINAL                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dados prontos para treinamento:

train_data = {
    'embeddings': [36471, 1536],       # SemÃ¢nticos (SBERT)
    'structural_features': [36471, 10], # Estruturais (10 features)
    'labels': [36471],                 # Pass/Fail
    'global_indices': [36471],         # Ãndices no grafo
    'df': df_train                     # DataFrame original
}

Grafo:
    edge_index: [2, 461493]   # Conectividade
    edge_weights: [461493]    # Pesos das arestas
    num_nodes: 2347           # Test cases Ãºnicos
```

---

## ğŸ”¬ Exemplo Concreto Completo: Test Case MCA-1015

Vamos acompanhar **MCA-1015** em TODAS as fases:

### **FASE 0: Dados Brutos**

```python
# df_train (linhas relevantes para MCA-1015):
   Build_ID      TC_Key        TE_Test_Result  CR_Count  TC_Summary
0  Build_001     MCA-1015      Pass            5         "Test API endpoint /users"
1  Build_002     MCA-1015      Pass            3         "Test API endpoint /users"
2  Build_003     MCA-1015      Fail            8         "Test API endpoint /users"
3  Build_004     MCA-1015      Fail            2         "Test API endpoint /users"
4  Build_005     MCA-1015      Pass            4         "Test API endpoint /users"
...
934 Build_935    MCA-1015      Pass            6         "Test API endpoint /users"

Total: 935 execuÃ§Ãµes (em 935 builds diferentes)
```

### **FASE 1: Embeddings**

```python
# TC embedding (SBERT)
tc_embedding_1015 = encode("Test API endpoint /users")
# shape: [768]
# valores: [0.234, -0.456, 0.678, ...]

# Commit embedding (agregado de 935 builds)
commit_embedding_1015 = encode("Add user validation; Fix auth bug; ...")
# shape: [768]

# Concatenado
embedding_1015 = np.concatenate([tc_embedding_1015, commit_embedding_1015])
# shape: [1536]
```

### **FASE 2: Features Estruturais**

```python
# 2.1. FIT: Construir histÃ³rico
extractor.tc_history['MCA-1015'] = {
    'executions': [
        (Build_001, 'Pass', date1, 5),
        (Build_002, 'Pass', date2, 3),
        (Build_003, 'Fail', date3, 8),
        (Build_004, 'Fail', date4, 2),
        (Build_005, 'Pass', date5, 4),
        # ... 930 mais
    ],
    'results': ['Pass', 'Pass', 'Fail', 'Fail', 'Pass', ..., 'Pass'],
    'total_execs': 935,
    'failures': 225,
    'passes': 710
}

# 2.2. TRANSFORM: Extrair features (para uma execuÃ§Ã£o especÃ­fica)
# Exemplo: linha do df_train onde Build_ID=Build_936 (novo build de treino)

features_1015 = extractor._extract_phylogenetic_features_v2(
    tc_key='MCA-1015',
    build_id='Build_936',
    is_test=False
)

# CÃ¡lculo das 10 features:
feature_vector = [
    935,        # 0. test_age (nÃºmero de builds onde executou)
    0.241,      # 1. failure_rate (225/935)
    0.400,      # 2. recent_failure_rate (Ãºltimos 5: [F, P, P, F, F] = 3/5)
    0.310,      # 3. flakiness_rate (transiÃ§Ãµes Passâ†”Fail)
    2,          # 4. consecutive_failures (Ãºltimos 2 builds falharam)
    5,          # 5. max_consecutive_failures (maior sequÃªncia histÃ³rica)
    0.159,      # 6. failure_trend (recent_rate - overall_rate = 0.40-0.241)
    4237,       # 7. commit_count (soma de CR_Count: 5+3+8+2+...+6)
    0,          # 8. test_novelty (0 = tem histÃ³rico, 1 = novo)
    892         # 9. cr_count (nÃºmero de code reviews)
]
# shape: [10]
```

### **FASE 3: ConstruÃ§Ã£o do Grafo**

```python
# 3.1. TC index
tc_to_idx['MCA-1015'] = 0  # MCA-1015 recebe Ã­ndice 0

# 3.2. Co-Failure edges
# Builds onde MCA-1015 falhou: [Build_003, Build_004, ..., Build_789] (225 builds)
# Para cada build, encontrar outros TCs que tambÃ©m falharam

# Exemplo: Build_003
# df_fail em Build_003:
#   TC_Key: MCA-1015, MCA-567, MCA-890
# Pares formados:
#   (MCA-1015, MCA-567) â† incrementa contador
#   (MCA-1015, MCA-890) â† incrementa contador
#   (MCA-567, MCA-890) â† incrementa contador

# ApÃ³s processar todos os 935 builds:
co_failure_counts[('MCA-1015', 'MCA-567')] = 45  # Falharam juntos 45 vezes
co_failure_counts[('MCA-1015', 'MCA-890')] = 12  # Falharam juntos 12 vezes

# Pesos:
# tc_failure_counts['MCA-1015'] = 225
# tc_failure_counts['MCA-567'] = 180
# tc_failure_counts['MCA-890'] = 90

weight_1015_567 = min(45/225, 45/180) = min(0.20, 0.25) = 0.20
weight_1015_890 = min(12/225, 12/90) = min(0.053, 0.133) = 0.053

# Apenas weight_1015_567 >= threshold (0.05), entÃ£o:
edges[(0, idx_567)] = {'co_failure': 0.20}  # Cria aresta
# weight_1015_890 < 0.05, aresta NÃƒO criada

# 3.3. Co-Success edges
# Builds onde MCA-1015 passou: 710 builds
# Processa similarmente...
# Resultado: MCA-1015 tem ~1500 co-success edges (passa com muitos TCs)

# 3.4. Semantic edges
# Calcula similaridade:
similarity(embedding_1015, embedding_567) = 0.45   # Baixo (TCs diferentes)
similarity(embedding_1015, embedding_1200) = 0.89  # ALTO! (TCs similares)

# Top-10 mais similares a MCA-1015:
# 1. MCA-1200: 0.89
# 2. MCA-1201: 0.87
# 3. MCA-1202: 0.85
# ...
# 10. MCA-1210: 0.76

# Cria 10 arestas semantic (todas >= 0.75)

# 3.5. Resultado final para MCA-1015:
edges_multi[(0, idx_567)] = {'co_failure': 0.20}
edges_multi[(0, idx_1200)] = {'semantic': 0.89}
edges_multi[(0, idx_1201)] = {'semantic': 0.87}
edges_multi[(0, idx_2)] = {'co_success': 0.95}
edges_multi[(0, idx_45)] = {'co_success': 0.92}
# ... ~1550 arestas total conectadas a MCA-1015
```

### **FASE 4: Edge Index (PyTorch Geometric)**

```python
# 4.1. Converter para formato PyG
edge_index = []
edge_weights = []

for (src, dst), edge_dict in edges_multi.items():
    # Combinar pesos
    weight = (
        edge_dict.get('co_failure', 0) * 1.0 +
        edge_dict.get('co_success', 0) * 0.5 +
        edge_dict.get('semantic', 0) * 0.3
    ) / (1.0 + 0.5 + 0.3)  # Normalizar

    # Adicionar ambas as direÃ§Ãµes (grafo nÃ£o-direcionado)
    edge_index.append([src, dst])
    edge_index.append([dst, src])
    edge_weights.extend([weight, weight])

# edge_index contendo MCA-1015 (idx=0):
edge_index = [
    [0, 567],    # MCA-1015 â†’ MCA-567
    [567, 0],    # MCA-567 â†’ MCA-1015 (bidirecional)
    [0, 1200],   # MCA-1015 â†’ MCA-1200
    [1200, 0],   # ...
    # ... ~3100 entradas (1550 arestas * 2)
]

edge_weights = [0.20, 0.20, 0.89, 0.89, ...]

# Converter para tensor
edge_index = torch.tensor(edge_index).T  # [2, num_edges]
edge_weights = torch.tensor(edge_weights)  # [num_edges]
```

---

## ğŸ“Š Resumo Visual: Linha do Tempo

```
TEMPO  â†’

t=0     Carregar DataFrames
        â””â”€ df_train: 36,471 linhas, 2,347 TCs Ãºnicos, 935 builds

t=1     Gerar Embeddings (SBERT)
        â””â”€ train_embeddings: [36471, 1536]
        â””â”€ Cache: embeddings_cache.pkl
        â””â”€ Tempo: ~10 minutos (com GPU)

t=2     FIT Structural Extractor
        â””â”€ Processa df_train
        â””â”€ ConstrÃ³i tc_history para 2,347 TCs
        â””â”€ Cache: structural_features_cache.pkl
        â””â”€ Tempo: ~2 minutos

t=3     TRANSFORM Features Estruturais
        â””â”€ train_struct: [36471, 10]
        â””â”€ val_struct: [5210, 10]
        â””â”€ test_struct: [10421, 10]
        â””â”€ Tempo: ~1 minuto

t=4     FIT Graph Builder
        â””â”€ Processa df_train + train_embeddings
        â””â”€ ConstrÃ³i grafo: 2,347 nodes, 461,493 edges
        â””â”€ Cache: multi_edge_graph.pkl
        â””â”€ Tempo: ~5 minutos

t=5     Extract Edge Index
        â””â”€ edge_index: [2, 461493]
        â””â”€ edge_weights: [461493]
        â””â”€ Tempo: instantÃ¢neo (jÃ¡ estÃ¡ pronto)

t=6     PRONTO PARA TREINAR!
        â””â”€ Total preprocessing: ~18 minutos
        â””â”€ PrÃ³ximos runs: ~1 segundo (tudo cacheado)
```

---

## ğŸ¯ ConclusÃ£o: Respostas Finais

| Pergunta | Resposta Curta | Detalhes |
|----------|----------------|----------|
| **Grafo construÃ­do com quais informaÃ§Ãµes?** | `df_train` + `train_embeddings` + configs | Co-failure/success usa builds e resultados. Semantic usa embeddings SBERT. |
| **"Tests failing together" = mesma build?** | âœ… **SIM** | Dois TCs que falharam no MESMO Build_ID |
| **TCs ocorrem em mÃºltiplos builds?** | âœ… **SIM** | Maioria aparece em 100-900 builds. Alguns em todos os 935. |
| **Aresta para cada ocorrÃªncia?** | âŒ **NÃƒO** | UMA aresta com peso agregado proporcional ao nÃºmero de co-ocorrÃªncias |
| **Quando features sÃ£o extraÃ­das?** | FIT (histÃ³rico) + TRANSFORM (features) | FIT = UMA VEZ. TRANSFORM = para cada amostra |

**Ordem cronolÃ³gica completa**:
1. Carregar dados
2. Gerar embeddings (SBERT)
3. FIT extractor (construir histÃ³rico)
4. TRANSFORM features (extrair 10 features)
5. FIT graph builder (construir grafo)
6. Extract edge_index (formato PyG)
7. **Pronto para treinar!**

---

**Documento criado em**: 2025-11-15
**Baseado em**: AnÃ¡lise detalhada do cÃ³digo Filo-Priori V8
**VersÃ£o**: 1.0 - ExplicaÃ§Ã£o Completa com Exemplos Concretos
