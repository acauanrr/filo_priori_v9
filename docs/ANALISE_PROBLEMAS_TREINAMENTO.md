# An√°lise de Problemas do Treinamento V8

**Data**: 2025-11-07
**Status**: üî¥ CRITICAL - Modelo n√£o aprendeu

---

## üìä Resultados Obtidos

```
Test Accuracy: 0.9039 (90.39%)
Test F1 Macro: 0.4748
Test APFD: 0.4969

Classification Report:
              precision    recall  f1-score   support
    Not-Pass       0.00      0.00      0.00       781  ‚ùå
    Pass           0.90      1.00      0.95      7346  ‚úì
```

---

## üî¥ PROBLEMA #1: COLAPSO DE PREDI√á√ÉO (CR√çTICO)

### Sintoma
- **Recall Not-Pass = 0.00%**: O modelo NUNCA detecta falhas
- **Recall Pass = 100%**: O modelo SEMPRE prev√™ Pass
- **Precision Not-Pass = 0.00%**: Nenhuma predi√ß√£o de Not-Pass

### Causa Raiz
**Desbalanceamento extremo de classes**:
- Pass: 61,224 (88.5%)
- Not-Pass: 7,945 (11.5%)
- Ratio: 7.7:1

**Focal Loss inadequado**:
```yaml
focal:
  alpha: [0.15, 0.85]  # Muito fraco!
  gamma: 2.0
```

O alpha=[0.15, 0.85] significa:
- Not-Pass (classe minorit√°ria): peso 0.15 ‚ùå
- Pass (classe majorit√°ria): peso 0.85 ‚ùå

**INVERTIDO!** Deveria ser alpha=[0.85, 0.15] ou mais!

### Por que Aconteceu?
1. **Focal Loss com alpha invertido**: Favoreceu a classe ERRADA
2. **Threshold 0.5**: Inadequado para classes desbalanceadas
3. **Learning rate baixo**: 5e-5 √© muito conservador
4. **Dropout alto**: 0.3-0.4 regularizou demais

---

## üî¥ PROBLEMA #2: F1 MACRO ESTAGNADO

### Sintoma
```
Epoch 1:  Val F1=0.4703
Epoch 2:  Val F1=0.4703
...
Epoch 13: Val F1=0.4703
```

**F1 id√™ntico em TODAS as √©pocas = modelo n√£o aprendeu**

### Explica√ß√£o
F1 Macro = (F1_NotPass + F1_Pass) / 2 = (0.00 + 0.94) / 2 = 0.47

O modelo est√° simplesmente repetindo a mesma predi√ß√£o (sempre Pass).

---

## üî¥ PROBLEMA #3: APFD MUITO BAIXO

### Resultados
```
Mean APFD: 0.4969
Builds analisados: 52 (esperado: 277)
```

### Por que?
- **APFD < 0.50 √© PIOR que random!**
- **Apenas 52 builds** com falhas (faltam 225 builds)
- Se o modelo nunca prev√™ Not-Pass, n√£o prioriza corretamente

---

## üî¥ PROBLEMA #4: CONFIGURA√á√ÉO INCORRETA

### Focal Loss Alpha Invertido
```yaml
# ‚ùå ERRADO (configura√ß√£o atual)
focal:
  alpha: [0.15, 0.85]  # [Not-Pass, Pass]
  # Peso 0.15 para classe minorit√°ria (Not-Pass) ‚ùå
  # Peso 0.85 para classe majorit√°ria (Pass) ‚ùå
```

**Deveria ser:**
```yaml
# ‚úÖ CORRETO
focal:
  alpha: [0.02, 0.98]  # [Not-Pass, Pass]
  # Peso 0.98 para classe minorit√°ria (Not-Pass) ‚úì
  # Peso 0.02 para classe majorit√°ria (Pass) ‚úì
  gamma: 3.0  # Aumentar tamb√©m
```

### Threshold Inadequado
```python
# Threshold padr√£o = 0.5
predictions = (probabilities[:, 1] > 0.5).astype(int)
```

**Para classes desbalanceadas, threshold deveria ser < 0.5**

---

## üîß SOLU√á√ïES IMPLEMENTADAS

### Solu√ß√£o 1: Corrigir Focal Loss (PRIORIT√ÅRIO)
```yaml
loss:
  type: "focal"
  focal:
    alpha: [0.02, 0.98]  # Invertido e mais agressivo
    gamma: 3.0  # Aumentado de 2.0 para 3.0
```

**L√≥gica do Focal Loss**:
```python
# Para classe minorit√°ria (Not-Pass, √≠ndice 0):
loss_weight_NotPass = alpha[0] * (1 - p_NotPass)^gamma
# Com alpha=0.98, d√° MUITO peso a erros de Not-Pass

# Para classe majorit√°ria (Pass, √≠ndice 1):
loss_weight_Pass = alpha[1] * (1 - p_Pass)^gamma
# Com alpha=0.02, d√° POUCO peso a erros de Pass
```

### Solu√ß√£o 2: Threshold Search
```python
# Testar thresholds de 0.1 a 0.9
best_threshold = find_best_threshold(
    val_probabilities,
    val_labels,
    metric='f1_macro'
)
# Provavelmente ser√° ~0.3-0.4
```

### Solu√ß√£o 3: Hiperpar√¢metros Ajustados
```yaml
training:
  learning_rate: 1e-4  # De 5e-5 ‚Üí 1e-4 (2x maior)
  weight_decay: 5e-5   # De 2e-4 ‚Üí 5e-5 (4x menor)

model:
  semantic:
    dropout: 0.2  # De 0.3 ‚Üí 0.2
  structural:
    dropout: 0.2  # De 0.3 ‚Üí 0.2
  classifier:
    dropout: 0.3  # De 0.4 ‚Üí 0.3
```

### Solu√ß√£o 4: Monitoramento de Diversidade
```python
def compute_prediction_diversity(predictions):
    """Detecta colapso de predi√ß√£o"""
    unique, counts = np.unique(predictions, return_counts=True)
    diversity = len(unique) / len(np.unique([0, 1]))  # 0.5 se colapso
    return diversity

# Adicionar √† avalia√ß√£o
if diversity < 0.3:
    logger.warning("‚ö†Ô∏è PREDICTION COLLAPSE DETECTED!")
```

### Solu√ß√£o 5: Class Weights Alternativos
```python
# Se Focal Loss n√£o funcionar, usar Weighted CE
class_weights = torch.FloatTensor([7.7, 1.0])  # Ratio direto
criterion = nn.CrossEntropyLoss(weight=class_weights)
```

---

## üìã CONFIGURA√á√ÉO CORRIGIDA

Criar: `configs/experiment_v8_fixed.yaml`

```yaml
# Loss configurado corretamente
loss:
  type: "focal"
  focal:
    alpha: [0.02, 0.98]  # ‚úÖ Invertido e agressivo
    gamma: 3.0           # ‚úÖ Aumentado

  # Alternativa (se focal n√£o funcionar)
  weighted_ce:
    use_class_weights: true
    class_weights: [7.7, 1.0]  # Ratio direto

# Training ajustado
training:
  num_epochs: 50         # Aumentar de 40
  batch_size: 32
  learning_rate: 1e-4    # ‚úÖ 2x maior (de 5e-5)
  weight_decay: 5e-5     # ‚úÖ 4x menor (de 2e-4)

  early_stopping:
    patience: 20  # ‚úÖ Aumentar de 12
    monitor: "val_f1_macro"
    min_delta: 0.001  # ‚úÖ Adicionar

# Model com menos regulariza√ß√£o
model:
  semantic:
    dropout: 0.2  # ‚úÖ De 0.3
  structural:
    dropout: 0.2  # ‚úÖ De 0.3
  classifier:
    dropout: 0.3  # ‚úÖ De 0.4

# Threshold search
evaluation:
  threshold_search:
    enabled: true
    search_range: [0.1, 0.9]  # ‚úÖ Mais amplo
    search_step: 0.05
    metric: "f1_macro"
```

---

## üéØ CRIT√âRIOS DE SUCESSO (REVISADOS)

### M√≠nimo Aceit√°vel (GO Criteria)
- [ ] **Prediction Diversity ‚â• 0.30**: Ambas classes sendo previstas
- [ ] **Recall Not-Pass ‚â• 0.30**: Detectando pelo menos 30% das falhas
- [ ] **F1 Macro ‚â• 0.55**: Balanceado entre classes
- [ ] **Test Accuracy ‚â• 0.70**: Performance geral
- [ ] **APFD ‚â• 0.55**: Melhor que random

### Target (Ideal)
- [ ] Prediction Diversity ‚â• 0.40
- [ ] Recall Not-Pass ‚â• 0.50
- [ ] F1 Macro ‚â• 0.60
- [ ] Test Accuracy ‚â• 0.75
- [ ] APFD ‚â• 0.60

### NO-GO (Falha Cr√≠tica)
- ‚ùå Prediction Diversity < 0.20 (colapso)
- ‚ùå Recall Not-Pass < 0.20 (n√£o detecta falhas)
- ‚ùå F1 Macro < 0.50 (pior que baseline)

---

## üî¥ PROBLEMA #5: ESTRAT√âGIA BIN√ÅRIA INCORRETA (CR√çTICO!)

### Descoberta
**Usu√°rio clarificou**: "N√£o, n√£o √© pra incluir Delete/Blocked apenas 'Fail'.. 'Pass' e 'Fail'"

O modelo deve classificar APENAS:
- ‚úÖ Pass (classe 1)
- ‚úÖ Fail (classe 0)

E EXCLUIR do dataset:
- ‚ùå Delete (3,653 amostras)
- ‚ùå Blocked (1,862 amostras)
- ‚ùå Conditional Pass (654 amostras)
- ‚ùå Pending (116 amostras)
- ‚ùå Outros

### Impacto da Mudan√ßa

#### Antes (pass_vs_all):
```yaml
binary_strategy: "pass_vs_all"
binary_negative_class: "Not-Pass"  # Agrupa Fail + Delete + Blocked + etc.
```
- Total: 69,169 amostras
- Pass: 61,224 (88.5%)
- Not-Pass: 7,945 (11.5%)
- Ratio: 7.7:1

#### Agora (pass_vs_fail):
```yaml
binary_strategy: "pass_vs_fail"  # ‚úÖ CORRETO
binary_negative_class: "Fail"  # APENAS Fail
```
- Total: ~62,878 amostras (redu√ß√£o de 6,291 amostras)
- Pass: 61,224 (97.4%)
- Fail: ~1,654 (2.6%)
- Ratio: 37:1 ‚ö†Ô∏è **5x MAIS DESBALANCEADO!**

### Corre√ß√£o Implementada

```yaml
# configs/experiment_v8_fixed.yaml

data:
  binary_strategy: "pass_vs_fail"  # ‚úÖ Mudado de "pass_vs_all"
  binary_negative_class: "Fail"    # ‚úÖ Mudado de "Not-Pass"

loss:
  focal:
    alpha: [0.995, 0.005]  # ‚úÖ Ajustado para ratio 37:1 (era [0.98, 0.02])
    gamma: 3.5             # ‚úÖ Aumentado de 3.0

  weighted_ce:  # Alternativa
    class_weights: [37.0, 1.0]  # ‚úÖ Ajustado (era [7.7, 1.0])
```

### Por que Isso √© Cr√≠tico?

1. **Sem√¢ntica Diferente**:
   - Delete ‚â† Fail (teste deletado por outros motivos)
   - Blocked ‚â† Fail (teste bloqueado, n√£o falhou)
   - Conditional Pass ‚â† Fail (passou com condi√ß√µes)

2. **Objetivo do Modelo**:
   - Queremos detectar FALHAS REAIS (Fail)
   - N√£o queremos misturar com outras classes

3. **APFD Afetado**:
   - Prioriza√ß√£o deve focar em testes que FALHAM
   - N√£o em testes deletados/bloqueados

### Novo Desafio: Imbalance Extremo (37:1)

**Problema**: Com 97.4% Pass / 2.6% Fail, o modelo pode facilmente colapsar novamente.

**Solu√ß√µes Aplicadas**:
1. Focal Loss muito mais agressivo: alpha=[0.995, 0.005], gamma=3.5
2. Threshold search mais amplo: [0.1, 0.9]
3. Considerar SMOTE ou class weights alternativos
4. Monitoramento rigoroso de diversidade de predi√ß√£o

---

## üîÑ PLANO DE A√á√ÉO

### Fase 0: Corre√ß√µes Cr√≠ticas (COMPLETO ‚úÖ)
1. ‚úÖ Criar `configs/experiment_v8_fixed.yaml`
2. ‚úÖ Mudar binary_strategy: "pass_vs_all" ‚Üí "pass_vs_fail"
3. ‚úÖ Ajustar Focal Loss: alpha=[0.995, 0.005], gamma=3.5
4. ‚úÖ Ajustar hiperpar√¢metros (lr, dropout, weight_decay)
5. ‚úÖ Documentar mudan√ßas em ANALISE_PROBLEMAS_TREINAMENTO.md

### Fase 1: Teste R√°pido (PR√ìXIMO PASSO)
1. ‚è≥ Rodar treino de teste (10 √©pocas, sample 5K)
   ```bash
   python main_v8.py --config configs/experiment_v8_fixed.yaml \
                      --sample-size 5000 \
                      --num-epochs 10
   ```
2. ‚è≥ Verificar m√©tricas cr√≠ticas:
   - Prediction Diversity > 0.15
   - Recall Fail > 0.20
   - F1 Macro > 0.45
3. ‚è≥ Se falhar, considerar alternativas (ver Fase 4)

### Fase 2: Threshold Search (SE NECESS√ÅRIO)
1. ‚è≥ Implementar threshold search
2. ‚è≥ Encontrar melhor threshold
3. ‚è≥ Atualizar c√≥digo de predi√ß√£o

### Fase 3: Treino Completo (SE FASE 1 OK)
1. ‚è≥ Rodar treino completo (50 √©pocas)
2. ‚è≥ Monitorar m√©tricas a cada √©poca
3. ‚è≥ Salvar melhores pesos

### Fase 4: Alternativa Weighted CE (SE FOCAL FALHAR)
1. ‚è≥ Substituir Focal Loss por Weighted CE
2. ‚è≥ class_weights = [7.7, 1.0]
3. ‚è≥ Re-treinar

---

## üìä COMPARA√á√ÉO: ANTES vs DEPOIS (ESPERADO)

| M√©trica | Antes (‚ùå) | Esperado (‚úÖ) | Notas |
|---------|-----------|--------------|-------|
| **Binary Strategy** | pass_vs_all | pass_vs_fail | ‚úÖ CR√çTICO |
| **Dataset Size** | 69,169 | 62,878 | -6,291 amostras |
| **Class Ratio** | 88.5%/11.5% (7.7:1) | 97.4%/2.6% (37:1) | 5x mais desbalanceado |
| **Recall Fail** | 0.00% | ‚â•30% | Meta principal |
| **Recall Pass** | 100% | ‚â•95% | Deve permanecer alto |
| **Precision Fail** | 0.00% | ‚â•25% | Evitar falsos alarmes |
| **F1 Macro** | 0.47 | ‚â•0.50 | Balanceado |
| **Prediction Diversity** | ~0.0 | ‚â•0.20 | Colapso detectado |
| **APFD** | 0.497 | ‚â•0.55 | Prioriza√ß√£o melhor |
| **Focal Loss Alpha** | [0.15, 0.85] | [0.995, 0.005] | 66x mais agressivo |
| **√âpocas at√© convergir** | 13 (estagnado) | 20-35 | Com aprendizado real |

---

## üö® SINAIS DE ALERTA (Red Flags)

Durante o treinamento, monitorar:

1. **Colapso de Predi√ß√£o**:
   ```
   ‚ö†Ô∏è WARNING: All predictions are class 1 (Pass)
   ‚ö†Ô∏è Prediction diversity: 0.00
   ```

2. **F1 Estagnado**:
   ```
   Epoch 1-10: Val F1 = 0.47 (sem varia√ß√£o)
   ```

3. **Loss n√£o diminuindo**:
   ```
   Train Loss: 0.027 ‚Üí 0.026 ‚Üí 0.025 (muito lento)
   ```

4. **Gradientes muito pequenos**:
   ```
   Avg gradient norm < 1e-5
   ```

---

## üí° LI√á√ïES APRENDIDAS

1. **Alpha no Focal Loss √© contra-intuitivo**:
   - N√ÉO √© "peso da classe"
   - √â "fator de down-weight para exemplos f√°ceis"
   - Classe minorit√°ria precisa de alpha ALTO (0.9-0.98)
   - Classe majorit√°ria precisa de alpha BAIXO (0.02-0.1)

2. **Threshold 0.5 √© inadequado para classes desbalanceadas**:
   - Sempre usar threshold search
   - Threshold √≥timo geralmente √© ~0.3-0.4

3. **Early stopping muito agressivo**:
   - patience=12 √© pouco para modelos complexos
   - Usar patience=20-30

4. **Regulariza√ß√£o excessiva**:
   - Dropout 0.3-0.4 + weight_decay 2e-4 √© muito
   - Reduzir ambos

---

## üìÅ ARQUIVOS AFETADOS

- ‚úÖ `configs/experiment_v8_fixed.yaml` (CRIADO E CORRIGIDO)
  - binary_strategy: "pass_vs_fail" ‚úÖ
  - Focal Loss: alpha=[0.995, 0.005], gamma=3.5 ‚úÖ
  - Hiperpar√¢metros ajustados ‚úÖ
- ‚úÖ `ANALISE_PROBLEMAS_TREINAMENTO.md` (ATUALIZADO)
  - Problema #5: Binary Strategy documentado ‚úÖ
- ‚è≥ `main_v8.py` (threshold search j√° existe)
- ‚è≥ `src/training/losses.py` (verificar implementa√ß√£o focal loss)
- ‚è≥ `src/evaluation/metrics.py` (adicionar diversidade)

---

**Status**: üü° **CORRE√á√ïES IMPLEMENTADAS - PRONTO PARA TESTE**

**Pr√≥ximo passo**: Rodar teste r√°pido (10 √©pocas, 5K samples)
```bash
python main_v8.py --config configs/experiment_v8_fixed.yaml \
                   --sample-size 5000 \
                   --num-epochs 10
```
